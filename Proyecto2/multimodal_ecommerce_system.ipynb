{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-uR45ko2asx"
      },
      "source": [
        "# Sistema de Recuperación Multimodal de Información para E-Commerce\n",
        "\n",
        "**Proyecto de Recuperación de Información - 2do Bimestre**\n",
        "\n",
        "Este notebook implementa un sistema completo de búsqueda multimodal con:\n",
        "- Búsqueda texto → productos\n",
        "- Búsqueda imagen → productos  \n",
        "- Re-ranking de resultados\n",
        "- Generación aumentada por recuperación (RAG)\n",
        "- Búsqueda conversacional con contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMBAkJjU2asz"
      },
      "source": [
        "## 1. Instalación de Dependencias"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalación de librerías base para el procesamiento de visión por computadora (torch, torchvision), procesamiento de lenguaje natural (sentence-transformers) y gestión de bases de datos vectoriales (chromadb). También se incluyen herramientas para la creación de interfaces rápidas (gradio) y la comunicación con la API de Kaggle."
      ],
      "metadata": {
        "id": "8Jg81yqMW37W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IQsmiOW2as0",
        "outputId": "d615bb24-552c-4f18-8fd7-92cc8e3786fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# MODELOS DE DEEP LEARNING\n",
        "!pip install -q torch torchvision ftfy regex tqdm\n",
        "# torch: Framework de deep learning principal (PyTorch)\n",
        "\n",
        "# MODELO MULTIMODAL CLIP\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n",
        "# CLIP: Contrastive Language-Image Pre-training (OpenAI)\n",
        "\n",
        "# RE-RANKING\n",
        "!pip install -q sentence-transformers\n",
        "# sentence-transformers: Framework para embeddings de texto semánticos\n",
        "\n",
        "# BASE DE DATOS VECTORIAL\n",
        "!pip install -q chromadb\n",
        "# chromadb: Base de datos vectorial embeddings-first\n",
        "\n",
        "# INTERFAZ DE USUARIO\n",
        "!pip install -q gradio\n",
        "# gradio: Framework para crear interfaces web interactivas\n",
        "\n",
        "# PROCESAMIENTO DE IMÁGENES\n",
        "!pip install -q Pillow\n",
        "# Pillow: Python Imaging Library (PIL)\n",
        "\n",
        "# MANIPULACIÓN DE DATOS\n",
        "!pip install -q pandas\n",
        "# pandas: Librería de análisis de datos\n",
        "\n",
        "# DESCARGA DE DATASETS\n",
        "!pip install -q kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioUGonue2as1"
      },
      "source": [
        "## 2. Configuración de Kaggle y Descarga del Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autenticación con Kaggle mediante el archivo de credenciales kaggle.json. El objetivo es automatizar la descarga y descompresión del dataset de Amazon directamente en el almacenamiento temporal de la sesión de Colab"
      ],
      "metadata": {
        "id": "ehMllds7XL5r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "QgWdAvl92as1",
        "outputId": "31dac300-2b76-4228-c22a-ff10fab3cf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo kaggle.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e29981bd-019f-4c5c-90f0-84cbb8daac31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e29981bd-019f-4c5c-90f0-84cbb8daac31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Credenciales de Kaggle configuradas\n"
          ]
        }
      ],
      "source": [
        "# Subir Archivo kaggle.json\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Archivo kaggle.json\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Configurar credenciales de Kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"Credenciales de Kaggle configuradas\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "# Pandas: Librería de análisis de datos\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Descarga automática (esto baja el .zip, lo extrae y te da la ruta)\n",
        "path = kagglehub.dataset_download(\"datafiniti/consumer-reviews-of-amazon-products\")\n",
        "\n",
        "# 2. Listar archivos para estar seguros del nombre\n",
        "print(\"Archivos en la carpeta:\", os.listdir(path))\n",
        "\n",
        "# 3. Cargar el archivo\n",
        "file_path = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "TBoMmizoLem2",
        "outputId": "776e7ab4-7e96-4570-f6e0-d381676fbb68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'consumer-reviews-of-amazon-products' dataset.\n",
            "Archivos en la carpeta: ['Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv', '1429_1.csv', 'Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id             dateAdded           dateUpdated  \\\n",
              "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "3  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "4  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "\n",
              "                                                name                  asins  \\\n",
              "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "3  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "4  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "\n",
              "          brand                                         categories  \\\n",
              "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "3  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "4  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "\n",
              "  primaryCategories                                          imageURLs  \\\n",
              "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "3   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "4   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "\n",
              "                                                keys  ... reviews.didPurchase  \\\n",
              "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "3  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "4  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "\n",
              "  reviews.doRecommend reviews.id reviews.numHelpful reviews.rating  \\\n",
              "0                 NaN        NaN                NaN              3   \n",
              "1                 NaN        NaN                NaN              4   \n",
              "2                 NaN        NaN                NaN              5   \n",
              "3                 NaN        NaN                NaN              5   \n",
              "4                 NaN        NaN                NaN              5   \n",
              "\n",
              "                                  reviews.sourceURLs  \\\n",
              "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "3  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "4  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  I order 3 of them and one of the item is bad q...   \n",
              "1  Bulk is always the less expensive way to go fo...   \n",
              "2  Well they are not Duracell but for the price i...   \n",
              "3  Seem to work as well as name brand batteries a...   \n",
              "4  These batteries are very long lasting the pric...   \n",
              "\n",
              "                                       reviews.title  reviews.username  \\\n",
              "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
              "1  ... always the less expensive way to go for pr...              ByMG   \n",
              "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
              "3  ... as well as name brand batteries at a much ...     Bymark sexson   \n",
              "4  ... batteries are very long lasting the price ...           Bylinda   \n",
              "\n",
              "                                          sourceURLs  \n",
              "0  https://www.barcodable.com/upc/841710106442,ht...  \n",
              "1  https://www.barcodable.com/upc/841710106442,ht...  \n",
              "2  https://www.barcodable.com/upc/841710106442,ht...  \n",
              "3  https://www.barcodable.com/upc/841710106442,ht...  \n",
              "4  https://www.barcodable.com/upc/841710106442,ht...  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79b226fa-34e3-4b13-8528-39f871e929b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>...</th>\n",
              "      <th>reviews.didPurchase</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>... 3 of them and one of the item is bad quali...</td>\n",
              "      <td>Byger yang</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>... always the less expensive way to go for pr...</td>\n",
              "      <td>ByMG</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>... are not Duracell but for the price i am ha...</td>\n",
              "      <td>BySharon Lambert</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>... as well as name brand batteries at a much ...</td>\n",
              "      <td>Bymark sexson</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>... batteries are very long lasting the price ...</td>\n",
              "      <td>Bylinda</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79b226fa-34e3-4b13-8528-39f871e929b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79b226fa-34e3-4b13-8528-39f871e929b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79b226fa-34e3-4b13-8528-39f871e929b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xC7z-eN2as3"
      },
      "source": [
        "## 3. Importaciones y Configuración"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se cargan los módulos necesarios y se configuran los modelos pre-entrenados. Se inicializa CLIP (ViT-B/32) para la generación de embeddings multimodales y un Cross-Encoder especializado en MS-MARCO para las tareas de reordenamiento de relevancia (re-ranking)"
      ],
      "metadata": {
        "id": "5wnRj9OhZZfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OlUEuj1p2as3"
      },
      "outputs": [],
      "source": [
        "# DEEP LEARNING Y MODELOS NEURONALES\n",
        "import torch\n",
        "# PyTorch: Framework principal de deep learning\n",
        "import clip\n",
        "# CLIP de OpenAI: Modelo multimodal texto-imagen\n",
        "\n",
        "# MANIPULACIÓN DE DATOS\n",
        "import numpy as np\n",
        "# NumPy: Operaciones numéricas y arrays\n",
        "\n",
        "# PROCESAMIENTO DE IMÁGENES\n",
        "from PIL import Image\n",
        "# Python Imaging Library (Pillow)\n",
        "\n",
        "# BASE DE DATOS VECTORIAL\n",
        "import chromadb\n",
        "# ChromaDB: Base de datos para embeddings\n",
        "\n",
        "# RE-RANKING\n",
        "from sentence_transformers import CrossEncoder\n",
        "# Sentence-Transformers: Framework para embeddings semánticos\n",
        "\n",
        "# INTERFAZ DE USUARIO\n",
        "import gradio as gr\n",
        "# Gradio: Creación de UIs web interactivas\n",
        "\n",
        "# UTILIDADES DEL SISTEMA\n",
        "import json\n",
        "# Manejo de JSON\n",
        "\n",
        "from pathlib import Path\n",
        "# Manejo moderno de rutas de archivos\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Suprimir warnings molestos (ej: deprecation warnings)\n",
        "\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from io import BytesIO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONFIGURACIÓN DE HARDWARE"
      ],
      "metadata": {
        "id": "nUyFmbMSERgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "se detecta la disponibilidad de GPU (CUDA)"
      ],
      "metadata": {
        "id": "IND6yMWmZlEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detectar si hay GPU disponible (NVIDIA CUDA)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7CyAV7UDai8",
        "outputId": "9702821c-cb58-4de1-8cbc-ab283fe0dd31"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CARGA DE MODELOS"
      ],
      "metadata": {
        "id": "8E0T6GMhEYj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO CLIP\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "print(\" Modelo CLIP cargado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC15TuGpEHsx",
        "outputId": "52f6d93d-babb-4c5a-ed93-69c39c2cdf79"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modelo CLIP cargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODELO DE RE-RANKING\n",
        "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "print(\"Modelo de re-ranking cargado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "57d5e1b614ab40beaae9226540ca391f",
            "000161cf52f64ef8b3852253515170c3",
            "5764e887a9bd4f809c370e33639bef31",
            "54d3f19037e04dd8a0038225dcea07d8",
            "be571a9848644980a85c6453a5e3a6bb",
            "24476a86e80d469e8db7d8ca6c47fd63",
            "eacddb021ed64be09587b35e7dcd2d34",
            "0bc198cca9704f8e94f55c4a929d9e9a",
            "8f5207a58fff46048095f5f3645aba1e",
            "e6e219c7f5124dee955c0921be3afaea",
            "df586452ee004ba58e2a2282febeaed2"
          ]
        },
        "id": "TT5Uq2RbEKj0",
        "outputId": "1ee8901d-121d-4ab5-9cc7-567b8c2ef7bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57d5e1b614ab40beaae9226540ca391f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo de re-ranking cargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcnNfwu02as4"
      },
      "source": [
        "## 4. Preprocesamiento del Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consiste en la limpieza y estructuración de los datos crudos. Se filtran productos sin información esencial, se gestionan valores nulos y se construye una \"descripción enriquecida\" que combina el nombre, la categoría y la subcategoría del producto para maximizar la calidad de las búsquedas semánticas."
      ],
      "metadata": {
        "id": "3fqmunPGZt-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def preprocess_amazon_reviews_all_files(path, max_products=5000, min_reviews_per_product=1):\n",
        "    \"\"\"\n",
        "    Preprocesa TODOS los archivos CSV del dataset de Amazon para máxima cobertura.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    path : str\n",
        "        Ruta al directorio con los archivos CSV\n",
        "    max_products : int\n",
        "        Número máximo de productos únicos a mantener\n",
        "    min_reviews_per_product : int\n",
        "        Mínimo de reviews que debe tener un producto para incluirlo\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        DataFrame preprocesado con productos únicos y todas sus reviews\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"PREPROCESAMIENTO DE MÚLTIPLES ARCHIVOS\")\n",
        "    # ==================== PASO 1: CARGAR TODOS LOS ARCHIVOS ====================\n",
        "    print(\"\\nPaso 1: Cargando todos los archivos CSV...\")\n",
        "\n",
        "    # Lista de archivos CSV en el directorio\n",
        "    csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
        "    print(f\"   Archivos encontrados: {csv_files}\\n\")\n",
        "\n",
        "    # Cargar y combinar todos los DataFrames\n",
        "    dataframes = []\n",
        "    total_rows = 0\n",
        "\n",
        "    for i, csv_file in enumerate(csv_files, 1):\n",
        "        file_path = os.path.join(path, csv_file)\n",
        "        print(f\"   [{i}/{len(csv_files)}] Cargando {csv_file}...\", end=\" \")\n",
        "\n",
        "        try:\n",
        "            df_temp = pd.read_csv(file_path, low_memory=False)\n",
        "            rows = len(df_temp)\n",
        "            total_rows += rows\n",
        "            dataframes.append(df_temp)\n",
        "            print(f\"{rows:,} filas\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    # Combinar todos los DataFrames\n",
        "    print(f\"\\n Combinando {len(dataframes)} DataFrames...\")\n",
        "    df_all = pd.concat(dataframes, ignore_index=True)\n",
        "    print(f\" Total combinado: {len(df_all):,} filas\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 2: LIMPIEZA BÁSICA ====================\n",
        "    print(\"\\nPaso 2: Limpieza básica\")\n",
        "\n",
        "    initial_rows = len(df_all)\n",
        "\n",
        "    # Eliminar duplicados exactos\n",
        "    df_all = df_all.drop_duplicates()\n",
        "    print(f\" Duplicados eliminados: {initial_rows - len(df_all):,}\")\n",
        "\n",
        "    # Verificar columnas disponibles\n",
        "    print(f\"\\n Columnas disponibles: {df_all.columns.tolist()}\")\n",
        "\n",
        "    # Normalizar nombres de columnas (algunos archivos pueden tener variaciones)\n",
        "    # Mapeo de posibles nombres alternativos\n",
        "    column_mapping = {\n",
        "        'reviews.rating': ['rating', 'reviews.rating', 'review.rating'],\n",
        "        'reviews.text': ['text', 'reviews.text', 'review.text'],\n",
        "        'reviews.title': ['title', 'reviews.title', 'review.title'],\n",
        "        'reviews.username': ['username', 'reviews.username', 'review.username']\n",
        "    }\n",
        "\n",
        "    # Aplicar mapeo si es necesario\n",
        "    for standard_name, alternatives in column_mapping.items():\n",
        "        if standard_name not in df_all.columns:\n",
        "            for alt in alternatives:\n",
        "                if alt in df_all.columns:\n",
        "                    df_all[standard_name] = df_all[alt]\n",
        "                    break\n",
        "\n",
        "    # Identificar columnas críticas\n",
        "    required_columns = ['name', 'imageURLs']\n",
        "    optional_columns = ['id', 'brand', 'categories', 'primaryCategories',\n",
        "                       'reviews.text', 'reviews.rating', 'reviews.title',\n",
        "                       'reviews.username', 'asins']\n",
        "\n",
        "    # Verificar que existan las columnas requeridas\n",
        "    missing_cols = [col for col in required_columns if col not in df_all.columns]\n",
        "    if missing_cols:\n",
        "        print(f\"  Columnas faltantes: {missing_cols}\")\n",
        "        print(\"   Intentar columnas alternativas\")\n",
        "\n",
        "    # Eliminar filas sin información crítica\n",
        "    df_clean = df_all.dropna(subset=['name', 'imageURLs']).copy()\n",
        "    print(f\"Eliminadas {len(df_all) - len(df_clean):,} filas sin nombre o imagen\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 3: PROCESAR IMÁGENES ====================\n",
        "    print(\"\\nPaso 3: Procesar URLs de imágenes\")\n",
        "\n",
        "    def extract_first_image(image_urls):\n",
        "        \"\"\"Extrae la primera URL válida de imágenes\"\"\"\n",
        "        if pd.isna(image_urls):\n",
        "            return None\n",
        "        # Las URLs pueden venir separadas por comas o como lista\n",
        "        urls_str = str(image_urls)\n",
        "        # Limpiar caracteres extraños\n",
        "        urls_str = urls_str.replace('[', '').replace(']', '').replace('\"', '').replace(\"'\", '')\n",
        "        urls = urls_str.split(',')\n",
        "\n",
        "        # Tomar primera URL válida (HTTPS prioritario)\n",
        "        for url in urls:\n",
        "            url = url.strip()\n",
        "            if url.startswith('https://'):\n",
        "                return url\n",
        "        # Si no hay HTTPS, aceptar HTTP\n",
        "        for url in urls:\n",
        "            url = url.strip()\n",
        "            if url.startswith('http://'):\n",
        "                return url\n",
        "        return None\n",
        "\n",
        "    df_clean['image'] = df_clean['imageURLs'].apply(extract_first_image)\n",
        "\n",
        "    # Contar imágenes válidas\n",
        "    valid_images = df_clean['image'].notna().sum()\n",
        "    df_clean = df_clean.dropna(subset=['image'])\n",
        "    print(f\"URLs válidas extraídas: {len(df_clean):,}\")\n",
        "    print(f\"Imágenes HTTPS: {df_clean['image'].str.startswith('https').sum():,}\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 4: CREAR ID ÚNICO DE PRODUCTO ====================\n",
        "    print(\"\\nPaso 4: Generar IDs únicos de productos\")\n",
        "\n",
        "    # Usar columna 'id' si existe, sino crear hash del nombre\n",
        "    if 'id' in df_clean.columns:\n",
        "        df_clean['product_id'] = df_clean['id']\n",
        "    else:\n",
        "        # Crear ID basado en hash del nombre (más robusto que solo nombre)\n",
        "        df_clean['product_id'] = df_clean['name'].apply(\n",
        "            lambda x: abs(hash(str(x).strip().lower())) % (10 ** 10)\n",
        "        )\n",
        "\n",
        "    unique_products = df_clean['product_id'].nunique()\n",
        "    print(f\"Productos únicos identificados: {unique_products:,}\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 5: AGRUPAR REVIEWS POR PRODUCTO ====================\n",
        "    print(\"\\nPaso 5: Agrupar reviews por producto\")\n",
        "\n",
        "    products_dict = defaultdict(lambda: {\n",
        "        'reviews_texts': [],\n",
        "        'reviews_ratings': [],\n",
        "        'reviews_titles': [],\n",
        "        'reviews_usernames': []\n",
        "    })\n",
        "\n",
        "    # Procesar con barra de progreso\n",
        "    chunk_size = 10000\n",
        "    total_chunks = (len(df_clean) // chunk_size) + 1\n",
        "\n",
        "    for chunk_idx in range(total_chunks):\n",
        "        start_idx = chunk_idx * chunk_size\n",
        "        end_idx = min((chunk_idx + 1) * chunk_size, len(df_clean))\n",
        "        chunk = df_clean.iloc[start_idx:end_idx]\n",
        "\n",
        "        for idx, row in chunk.iterrows():\n",
        "            product_id = row['product_id']\n",
        "\n",
        "            # Primera vez: guardar info básica del producto\n",
        "            if 'name' not in products_dict[product_id]:\n",
        "                products_dict[product_id]['name'] = row['name']\n",
        "                products_dict[product_id]['brand'] = row.get('brand', 'Unknown')\n",
        "                products_dict[product_id]['image'] = row['image']\n",
        "                products_dict[product_id]['categories'] = row.get('categories', '')\n",
        "                products_dict[product_id]['primaryCategories'] = row.get('primaryCategories', '')\n",
        "                products_dict[product_id]['asins'] = row.get('asins', '')\n",
        "\n",
        "            # Agregar review si existe\n",
        "            review_text = row.get('reviews.text')\n",
        "            if pd.notna(review_text) and str(review_text).strip():\n",
        "                products_dict[product_id]['reviews_texts'].append(str(review_text))\n",
        "                products_dict[product_id]['reviews_ratings'].append(\n",
        "                    float(row.get('reviews.rating', 0))\n",
        "                )\n",
        "                products_dict[product_id]['reviews_titles'].append(\n",
        "                    str(row.get('reviews.title', ''))\n",
        "                )\n",
        "                products_dict[product_id]['reviews_usernames'].append(\n",
        "                    str(row.get('reviews.username', ''))\n",
        "                )\n",
        "\n",
        "        # Progreso\n",
        "        if (chunk_idx + 1) % 10 == 0 or chunk_idx == total_chunks - 1:\n",
        "            progress = ((chunk_idx + 1) / total_chunks) * 100\n",
        "            print(f\"   Progreso: {progress:.1f}% ({end_idx:,}/{len(df_clean):,} filas)\", end='\\r')\n",
        "\n",
        "    print(f\"\\nAgrupación completada: {len(products_dict):,} productos únicos\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 6: CONSTRUIR DATAFRAME DE PRODUCTOS ====================\n",
        "    print(\"\\nPaso 6: Construir DataFrame de productos\")\n",
        "\n",
        "    products_list = []\n",
        "\n",
        "    for product_id, info in products_dict.items():\n",
        "        # Filtrar productos con pocas reviews\n",
        "        num_reviews = len(info['reviews_texts'])\n",
        "        if num_reviews < min_reviews_per_product:\n",
        "            continue\n",
        "\n",
        "        # Calcular estadísticas de ratings\n",
        "        ratings = [r for r in info['reviews_ratings'] if r > 0]\n",
        "        avg_rating = np.mean(ratings) if ratings else 0\n",
        "\n",
        "        # Concatenar todas las reviews (limitado para memoria)\n",
        "        # Tomar máximo 10 reviews más relevantes (las primeras)\n",
        "        max_reviews_to_keep = 10\n",
        "        reviews_to_keep = info['reviews_texts'][:max_reviews_to_keep]\n",
        "        all_reviews_text = ' | '.join(reviews_to_keep)\n",
        "\n",
        "        # Resumen: top 3 reviews para descripción\n",
        "        reviews_summary = ' '.join(info['reviews_texts'][:3])\n",
        "\n",
        "        # Extraer categoría principal\n",
        "        categories_str = str(info['categories'])\n",
        "        main_category = 'General'\n",
        "        if categories_str and categories_str != 'nan':\n",
        "            cats = categories_str.split(',')\n",
        "            main_category = cats[0].strip() if cats else 'General'\n",
        "\n",
        "        products_list.append({\n",
        "            'product_id': product_id,\n",
        "            'name': info['name'],\n",
        "            'brand': info['brand'],\n",
        "            'image': info['image'],\n",
        "            'main_category': main_category,\n",
        "            'categories': info['categories'],\n",
        "            'asins': info['asins'],\n",
        "            'num_reviews': num_reviews,\n",
        "            'avg_rating': round(avg_rating, 2),\n",
        "            'all_reviews': all_reviews_text,\n",
        "            'reviews_summary': reviews_summary\n",
        "        })\n",
        "\n",
        "    df_products = pd.DataFrame(products_list)\n",
        "    print(f\"DataFrame construido: {len(df_products):,} productos\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 7: CREAR DESCRIPCIONES ENRIQUECIDAS ====================\n",
        "    print(\"\\nPaso 7: Crear descripciones enriquecidas\")\n",
        "\n",
        "    def clean_text(text):\n",
        "        \"\"\"Limpia y normaliza texto para CLIP\"\"\"\n",
        "        if pd.isna(text) or not str(text).strip():\n",
        "            return \"\"\n",
        "        text = str(text)\n",
        "        # Remover HTML tags\n",
        "        text = re.sub(r'<[^>]+>', '', text)\n",
        "        # Remover URLs\n",
        "        text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "        # Remover caracteres especiales excesivos\n",
        "        text = re.sub(r'[^\\w\\s.,!?-]', ' ', text)\n",
        "        # Remover múltiples espacios\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        # Limitar longitud (CLIP tiene límite de tokens)\n",
        "        return text.strip()[:500]\n",
        "\n",
        "    # Descripción combinada optimizada para embeddings\n",
        "    df_products['description'] = df_products.apply(\n",
        "        lambda row: f\"{clean_text(row['name'])} {clean_text(row['brand'])} \"\n",
        "                   f\"{clean_text(row['main_category'])} \"\n",
        "                   f\"{clean_text(row['reviews_summary'])}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    print(f\"Descripciones creadas\")\n",
        "\n",
        "\n",
        "    # ==================== PASO 8: SELECCIÓN Y ORDENAMIENTO FINAL ====================\n",
        "    print(\"\\nPaso 8: Selección final de productos\")\n",
        "\n",
        "    # Ordenar por popularidad y calidad\n",
        "    # Criterio: num_reviews (60%) + avg_rating (40%)\n",
        "    df_products['popularity_score'] = (\n",
        "        0.6 * (df_products['num_reviews'] / df_products['num_reviews'].max()) +\n",
        "        0.4 * (df_products['avg_rating'] / 5.0)\n",
        "    )\n",
        "\n",
        "    df_products = df_products.sort_values('popularity_score', ascending=False)\n",
        "\n",
        "    # Limitar a max_products\n",
        "    if len(df_products) > max_products:\n",
        "        df_products = df_products.head(max_products)\n",
        "        print(f\"Seleccionados top {max_products:,} productos más relevantes\")\n",
        "    else:\n",
        "        print(f\"Total de productos: {len(df_products):,}\")\n",
        "\n",
        "    # Resetear índice\n",
        "    df_products = df_products.reset_index(drop=True)\n",
        "\n",
        "    # Añadir precio estimado basado en categoría\n",
        "    category_price_ranges = {\n",
        "        'Electronics': (50, 500),\n",
        "        'Computers': (100, 1500),\n",
        "        'Home': (20, 200),\n",
        "        'Beauty': (10, 100),\n",
        "        'Sports': (15, 300),\n",
        "        'Clothing': (15, 150)\n",
        "    }\n",
        "\n",
        "    def estimate_price(category):\n",
        "        \"\"\"Estima precio basado en categoría\"\"\"\n",
        "        for cat_name, (min_p, max_p) in category_price_ranges.items():\n",
        "            if cat_name.lower() in category.lower():\n",
        "                return f\"${np.random.randint(min_p, max_p)}\"\n",
        "        return f\"${np.random.randint(20, 200)}\"\n",
        "\n",
        "    df_products['price'] = df_products['main_category'].apply(estimate_price)\n",
        "\n",
        "\n",
        "    # ==================== RESUMEN FINAL ====================\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"PREPROCESAMIENTO COMPLETADO\")\n",
        "    print(f\"\\nRESUMEN:\")\n",
        "    print(f\"   • Total productos únicos: {len(df_products):,}\")\n",
        "    print(f\"   • Reviews totales procesadas: {df_products['num_reviews'].sum():,}\")\n",
        "    print(f\"   • Reviews por producto (promedio): {df_products['num_reviews'].mean():.1f}\")\n",
        "    print(f\"   • Reviews por producto (mediana): {df_products['num_reviews'].median():.0f}\")\n",
        "    print(f\"   • Rating promedio general: {df_products['avg_rating'].mean():.2f}\")\n",
        "    print(f\"   • Productos con 5+ reviews: {(df_products['num_reviews'] >= 5).sum():,}\")\n",
        "\n",
        "    print(f\"\\nTOP 10 CATEGORÍAS:\")\n",
        "    cat_counts = df_products['main_category'].value_counts().head(10)\n",
        "    for cat, count in cat_counts.items():\n",
        "        print(f\"   • {cat}: {count:,} productos\")\n",
        "\n",
        "    print(f\"\\nDISTRIBUCIÓN DE RATINGS:\")\n",
        "    for rating in [5, 4, 3, 2, 1]:\n",
        "        count = ((df_products['avg_rating'] >= rating - 0.5) &\n",
        "                 (df_products['avg_rating'] < rating + 0.5)).sum()\n",
        "        print(f\"   • {rating} estrellas: {count:,} productos\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "    return df_products\n"
      ],
      "metadata": {
        "id": "xzymjyNqmo5O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== EJECUCIÓN ====================\n",
        "# Usar la ruta donde descargaste el dataset\n",
        "products_df = preprocess_amazon_reviews_all_files(\n",
        "    path=path,                    # Ruta del kagglehub\n",
        "    max_products=5000,            # Máximo 5000 productos\n",
        "    min_reviews_per_product=1    # Al menos 1 review\n",
        ")\n",
        "\n",
        "# Verificar resultado\n",
        "print(\"\\nMUESTRA DE PRODUCTOS PROCESADOS:\")\n",
        "print(products_df[['name', 'brand', 'main_category', 'num_reviews', 'avg_rating']].head(10))\n",
        "\n",
        "# Guardar dataset procesado (recomendado)\n",
        "output_file = 'amazon_products_processed_full.csv'\n",
        "products_df.to_csv(output_file, index=False)\n",
        "print(f\"\\nDataset guardado en '{output_file}'\")\n",
        "print(f\"Tamaño del archivo: {os.path.getsize(output_file) / (1024**2):.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbVbI6nHg8iv",
        "outputId": "d3988a3f-7d47-4d36-9d05-a5d265b6f527"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREPROCESAMIENTO DE MÚLTIPLES ARCHIVOS\n",
            "\n",
            "Paso 1: Cargando todos los archivos CSV...\n",
            "   Archivos encontrados: ['Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv', '1429_1.csv', 'Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv']\n",
            "\n",
            "   [1/3] Cargando Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv... 5,000 filas\n",
            "   [2/3] Cargando 1429_1.csv... 34,660 filas\n",
            "   [3/3] Cargando Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv... 28,332 filas\n",
            "\n",
            " Combinando 3 DataFrames...\n",
            " Total combinado: 67,992 filas\n",
            "\n",
            "Paso 2: Limpieza básica\n",
            " Duplicados eliminados: 95\n",
            "\n",
            " Columnas disponibles: ['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand', 'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer', 'manufacturerNumber', 'reviews.date', 'reviews.dateAdded', 'reviews.dateSeen', 'reviews.doRecommend', 'reviews.id', 'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs', 'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs', 'reviews.didPurchase', 'reviews.userCity', 'reviews.userProvince']\n",
            "Eliminadas 34,660 filas sin nombre o imagen\n",
            "\n",
            "Paso 3: Procesar URLs de imágenes\n",
            "URLs válidas extraídas: 33,237\n",
            "Imágenes HTTPS: 33,237\n",
            "\n",
            "Paso 4: Generar IDs únicos de productos\n",
            "Productos únicos identificados: 69\n",
            "\n",
            "Paso 5: Agrupar reviews por producto\n",
            "   Progreso: 100.0% (33,237/33,237 filas)\n",
            "Agrupación completada: 69 productos únicos\n",
            "\n",
            "Paso 6: Construir DataFrame de productos\n",
            "DataFrame construido: 69 productos\n",
            "\n",
            "Paso 7: Crear descripciones enriquecidas\n",
            "Descripciones creadas\n",
            "\n",
            "Paso 8: Selección final de productos\n",
            "Total de productos: 69\n",
            "\n",
            "======================================================================\n",
            "PREPROCESAMIENTO COMPLETADO\n",
            "\n",
            "RESUMEN:\n",
            "   • Total productos únicos: 69\n",
            "   • Reviews totales procesadas: 33,237\n",
            "   • Reviews por producto (promedio): 481.7\n",
            "   • Reviews por producto (mediana): 57\n",
            "   • Rating promedio general: 4.49\n",
            "   • Productos con 5+ reviews: 53\n",
            "\n",
            "TOP 10 CATEGORÍAS:\n",
            "   • Fire Tablets: 14 productos\n",
            "   • Amazon Echo: 7 productos\n",
            "   • Tablets: 3 productos\n",
            "   • Amazon SMP: 3 productos\n",
            "   • eBook Readers: 3 productos\n",
            "   • Computers: 3 productos\n",
            "   • Computers & Accessories: 3 productos\n",
            "   • Consumer Electronics: 2 productos\n",
            "   • AA: 2 productos\n",
            "   • Electronics: 2 productos\n",
            "\n",
            "DISTRIBUCIÓN DE RATINGS:\n",
            "   • 5 estrellas: 51 productos\n",
            "   • 4 estrellas: 15 productos\n",
            "   • 3 estrellas: 2 productos\n",
            "   • 2 estrellas: 0 productos\n",
            "   • 1 estrellas: 1 productos\n",
            "\n",
            "======================================================================\n",
            "\n",
            "MUESTRA DE PRODUCTOS PROCESADOS:\n",
            "                                                name         brand  \\\n",
            "0  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
            "1  AmazonBasics AA Performance Alkaline Batteries...  Amazonbasics   \n",
            "2  Fire HD 8 Tablet with Alexa, 8 HD Display, 16 ...        Amazon   \n",
            "3  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...        Amazon   \n",
            "4  Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16...        Amazon   \n",
            "5  Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16...        Amazon   \n",
            "6  Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16...        Amazon   \n",
            "7  Brand New Amazon Kindle Fire 16gb 7\" Ips Displ...        Amazon   \n",
            "8  Fire Tablet, 7 Display, Wi-Fi, 16 GB - Include...        Amazon   \n",
            "9  All-New Fire HD 8 Tablet with Alexa, 8 HD Disp...        Amazon   \n",
            "\n",
            "                    main_category  num_reviews  avg_rating  \n",
            "0                              AA         8343        4.45  \n",
            "1                              AA         3728        4.45  \n",
            "2                    Fire Tablets         2443        4.60  \n",
            "3                    Fire Tablets         2370        4.58  \n",
            "4                       Computers         1986        4.55  \n",
            "5                    Fire Tablets         1676        4.53  \n",
            "6                    Fire Tablets         1429        4.53  \n",
            "7  Computers/Tablets & Networking         1405        4.52  \n",
            "8                    Fire Tablets         1395        4.49  \n",
            "9                    Fire Tablets          883        4.58  \n",
            "\n",
            "Dataset guardado en 'amazon_products_processed_full.csv'\n",
            "Tamaño del archivo: 0.25 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maWnY_r02as4"
      },
      "source": [
        "## 5. Codificación e Indexación Multimodal"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformación de los productos en embeddings multimodales. Preparar para analizar la calidad del espacio vectorial y cómo se relacionan las representaciones visuales con las textuales en el índice de ChromaDB."
      ],
      "metadata": {
        "id": "Ta6VKxuOhkfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Codifica textos usando CLIP text encoder."
      ],
      "metadata": {
        "id": "keicwOcFkZFO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "07RL49182as5"
      },
      "outputs": [],
      "source": [
        "def encode_texts(texts, batch_size=32, max_length=77):\n",
        "    \"\"\"\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    texts : list of str\n",
        "        Lista de descripciones de productos a codificar\n",
        "    batch_size : int\n",
        "        Tamaño del batch para procesamiento eficiente\n",
        "    max_length : int\n",
        "        Longitud máxima de tokens (CLIP límite = 77)\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    numpy.ndarray\n",
        "        Array de embeddings de forma (n_texts, 512)\n",
        "    \"\"\"\n",
        "    print(f\"\\nCodificar {len(texts)} descripciones de texto\")\n",
        "\n",
        "    embeddings = []\n",
        "    num_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "\n",
        "    # Procesar en batches con barra de progreso\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Texto\"):\n",
        "        batch = texts[i:i + batch_size]\n",
        "\n",
        "        # Tokenizar texto (CLIP maneja truncamiento automático)\n",
        "        # truncate=True: corta texto si excede 77 tokens\n",
        "        tokens = clip.tokenize(batch, truncate=True).to(device)\n",
        "\n",
        "        # Codificar sin calcular gradientes (más rápido)\n",
        "        with torch.no_grad():\n",
        "            # model.encode_text() retorna embeddings de 512 dims\n",
        "            text_features = model.encode_text(tokens)\n",
        "\n",
        "            # CRÍTICO: Normalizar a norma unitaria\n",
        "            # Esto permite usar similitud coseno = producto punto\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # Mover a CPU y convertir a numpy\n",
        "        embeddings.append(text_features.cpu().numpy())\n",
        "\n",
        "    # Concatenar todos los batches\n",
        "    all_embeddings = np.vstack(embeddings)\n",
        "\n",
        "    print(f\"   Embeddings de texto: {all_embeddings.shape}\")\n",
        "    print(f\"   Norma promedio: {np.linalg.norm(all_embeddings, axis=1).mean():.4f}\")\n",
        "\n",
        "    return all_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Codifica imágenes desde URLs usando CLIP image encoder.\n"
      ],
      "metadata": {
        "id": "YhjlXPlFkdRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_images(image_urls, batch_size=16, timeout=5):\n",
        "    \"\"\"\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    image_urls : list of str\n",
        "        Lista de URLs o rutas locales de imágenes de productos.\n",
        "    batch_size : int, opcional\n",
        "        Tamaño de batch lógico (NO implementado aún, se procesa imagen por imagen).\n",
        "        Se deja como parámetro para futura optimización.\n",
        "    timeout : int, opcional\n",
        "        Tiempo máximo de espera para descargar una imagen desde una URL (en segundos).\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    tuple:\n",
        "        - all_embeddings : np.ndarray\n",
        "            Array de embeddings de forma (n_imágenes, 512).\n",
        "            Las imágenes fallidas se representan con vectores de ceros.\n",
        "        - valid_indices : list of int\n",
        "            Índices de las imágenes procesadas exitosamente.\n",
        "        - failed_indices : list of int\n",
        "            Índices de las imágenes que fallaron (descarga, formato, etc.).\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nCodificar {len(image_urls)} imágenes de productos\")\n",
        "\n",
        "    embeddings = []\n",
        "    valid_indices = []\n",
        "    failed_indices = []\n",
        "\n",
        "    # Header para evitar bloqueos (Amazon, BestBuy, etc.)\n",
        "    headers = {\n",
        "        'User-Agent': (\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
        "            'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "            'Chrome/91.0.4472.124 Safari/537.36'\n",
        "        )\n",
        "    }\n",
        "\n",
        "    for i in tqdm(range(len(image_urls)), desc=\"Imágenes\"):\n",
        "        url = image_urls[i]\n",
        "\n",
        "        try:\n",
        "            # CARGA DE LA IMAGEN\n",
        "            if isinstance(url, str) and url.startswith('http'):\n",
        "                response = requests.get(url, timeout=timeout, headers=headers)\n",
        "                response.raise_for_status()\n",
        "                image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "\n",
        "            elif isinstance(url, str) and os.path.exists(url):\n",
        "                image = Image.open(url).convert('RGB')\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"URL o ruta inválida: {url}\")\n",
        "\n",
        "            # PREPROCESAMIENTO (CLIP)\n",
        "            # preprocess realiza:\n",
        "            # 1. Resize a 224x224\n",
        "            # 2. Center crop\n",
        "            # 3. Normalización estándar CLIP\n",
        "            # 4. Conversión a tensor\n",
        "            image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "            # CODIFICACIÓN\n",
        "            with torch.no_grad():\n",
        "                image_features = model.encode_image(image_input)\n",
        "\n",
        "                # NORMALIZACIÓN (CRÍTICA)\n",
        "                # Garantiza compatibilidad con embeddings de texto\n",
        "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            embeddings.append(image_features.cpu().numpy())\n",
        "            valid_indices.append(i)\n",
        "\n",
        "        except Exception as e:\n",
        "            # FALLBACK EN CASO DE ERROR\n",
        "            # Se usa un vector de ceros para mantener alineación\n",
        "            # Alternativa avanzada: embedding promedio del dataset\n",
        "            embeddings.append(np.zeros((1, 512)))\n",
        "            failed_indices.append(i)\n",
        "\n",
        "            # Mostrar errores de forma controlada (evita spam)\n",
        "            if len(failed_indices) <= 5 or len(failed_indices) % 10 == 1:\n",
        "                print(f\" Error en imagen {i}: {str(e)[:60]}\")\n",
        "\n",
        "    all_embeddings = np.vstack(embeddings)\n",
        "\n",
        "    success_rate = (len(valid_indices) / len(image_urls)) * 100\n",
        "    avg_norm = np.linalg.norm(all_embeddings, axis=1).mean()\n",
        "\n",
        "    print(f\"\\n Embeddings de imágenes: {all_embeddings.shape}\")\n",
        "    print(f\"   Imágenes exitosas: {len(valid_indices)} ({success_rate:.1f}%)\")\n",
        "    print(f\"   Imágenes fallidas: {len(failed_indices)}\")\n",
        "    print(f\"   Norma promedio: {avg_norm:.4f}\")\n",
        "\n",
        "    return all_embeddings, valid_indices, failed_indices\n"
      ],
      "metadata": {
        "id": "hDzrjfaqkRcP"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Combina embeddings de texto e imagen en representación híbrida."
      ],
      "metadata": {
        "id": "rwHnlM5kkzy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_embeddings(text_embeddings, image_embeddings,\n",
        "                       text_weight=0.5, image_weight=0.5):\n",
        "    \"\"\"\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    text_embeddings : numpy.ndarray\n",
        "        Embeddings de texto (n, 512)\n",
        "    image_embeddings : numpy.ndarray\n",
        "        Embeddings de imagen (n, 512)\n",
        "    text_weight : float\n",
        "        Peso del componente textual (0-1)\n",
        "    image_weight : float\n",
        "        Peso del componente visual (0-1)\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    numpy.ndarray\n",
        "        Embeddings combinados (n, 512), normalizados\n",
        "    \"\"\"\n",
        "    print(f\"\\nCombinar embeddings (texto: {text_weight}, imagen: {image_weight})...\")\n",
        "\n",
        "    # Promedio ponderado\n",
        "    combined = text_weight * text_embeddings + image_weight * image_embeddings\n",
        "\n",
        "    # RE-NORMALIZAR después de combinar (IMPORTANTE)\n",
        "    # Sin esto, la similitud coseno no funcionaría correctamente\n",
        "    norms = np.linalg.norm(combined, axis=1, keepdims=True)\n",
        "    combined_normalized = combined / norms\n",
        "\n",
        "    print(f\"   Embeddings combinados: {combined_normalized.shape}\")\n",
        "    print(f\"   Norma promedio: {np.linalg.norm(combined_normalized, axis=1).mean():.4f}\")\n",
        "\n",
        "    return combined_normalized"
      ],
      "metadata": {
        "id": "r3f7B79JkxH2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INDEXACIÓN CON CHROMADB"
      ],
      "metadata": {
        "id": "Y6KUdWZHk-EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Crea índice vectorial en ChromaDB para búsqueda eficiente."
      ],
      "metadata": {
        "id": "KSIkIVkKlFxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_index(embeddings, products_df, collection_name=\"products\"):\n",
        "    \"\"\"\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    embeddings : numpy.ndarray\n",
        "        Embeddings multimodales de productos (n, 512)\n",
        "    products_df : pandas.DataFrame\n",
        "        DataFrame con información de productos\n",
        "    collection_name : str\n",
        "        Nombre de la colección en ChromaDB\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    chromadb.Collection\n",
        "        Colección de ChromaDB lista para búsquedas\n",
        "    \"\"\"\n",
        "    print(f\"\\nCrear índice vectorial '{collection_name}'\")\n",
        "\n",
        "    # Inicializar cliente ChromaDB\n",
        "    client = chromadb.Client()\n",
        "\n",
        "    # Eliminar colección existente (si existe)\n",
        "    try:\n",
        "        client.delete_collection(collection_name)\n",
        "        print(f\"Colección existente eliminada\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Crear nueva colección\n",
        "    # hnsw:space=\"cosine\": Usar similitud coseno\n",
        "    # HNSW (Hierarchical Navigable Small World): Algoritmo de búsqueda ANN\n",
        "    collection = client.create_collection(\n",
        "        name=collection_name,\n",
        "        metadata={\n",
        "            \"hnsw:space\": \"cosine\",  # Métrica de distancia\n",
        "            \"description\": \"Amazon products multimodal embeddings\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"Colección creada con HNSW (similitud coseno)\")\n",
        "\n",
        "    # Preparar datos para indexar\n",
        "    print(f\" Agregar {len(embeddings)} productos al índice\")\n",
        "\n",
        "    # Convertir embeddings a lista (ChromaDB requiere este formato)\n",
        "    embeddings_list = embeddings.tolist()\n",
        "\n",
        "    # Preparar documentos (texto para contexto)\n",
        "    documents = products_df['description'].tolist()\n",
        "\n",
        "    # Preparar metadatos (info adicional del producto)\n",
        "    metadatas = []\n",
        "    for _, row in products_df.iterrows():\n",
        "        metadatas.append({\n",
        "            'name': str(row['name'])[:500],  # Limitar longitud\n",
        "            'brand': str(row.get('brand', 'Unknown'))[:100],\n",
        "            'image': str(row['image'])[:500],\n",
        "            'category': str(row.get('main_category', 'General'))[:100],\n",
        "            'price': str(row.get('price', 'N/A'))[:20],\n",
        "            'num_reviews': int(row.get('num_reviews', 0)),\n",
        "            'avg_rating': float(row.get('avg_rating', 0.0))\n",
        "        })\n",
        "\n",
        "    # Crear IDs únicos\n",
        "    ids = [f\"product_{i}\" for i in range(len(products_df))]\n",
        "\n",
        "    # AGREGAR AL ÍNDICE EN BATCHES (ChromaDB tiene límite por request)\n",
        "    batch_size = 1000\n",
        "    num_batches = (len(embeddings) + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in tqdm(range(0, len(embeddings), batch_size), desc=\"Indexando\"):\n",
        "        end_idx = min(i + batch_size, len(embeddings))\n",
        "\n",
        "        collection.add(\n",
        "            embeddings=embeddings_list[i:end_idx],\n",
        "            documents=documents[i:end_idx],\n",
        "            metadatas=metadatas[i:end_idx],\n",
        "            ids=ids[i:end_idx]\n",
        "        )\n",
        "\n",
        "    # Verificar índice\n",
        "    count = collection.count()\n",
        "    print(f\"\\n   Índice creado exitosamente\")\n",
        "    print(f\"   Total productos indexados: {count:,}\")\n",
        "\n",
        "    # Estadísticas del índice\n",
        "    print(f\"\\nÍNDICE:\")\n",
        "    print(f\"   • Dimensión de embeddings: 512\")\n",
        "    print(f\"   • Algoritmo: HNSW (Approximate Nearest Neighbors)\")\n",
        "    print(f\"   • Métrica de similitud: Coseno\")\n",
        "    print(f\"   • Complejidad búsqueda: O(log n)\")\n",
        "    print(f\"   • Memoria estimada: {(count * 512 * 4) / (1024**2):.2f} MB\")\n",
        "\n",
        "    return collection"
      ],
      "metadata": {
        "id": "uUeByY_1k-iR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### EJECUCIÓN COMPLETA"
      ],
      "metadata": {
        "id": "plzNn7ANlh3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CODIFICACIÓN E INDEXACIÓN MULTIMODAL\")\n",
        "\n",
        "# PASO 1: Codificar textos\n",
        "text_embeddings = encode_texts(\n",
        "    products_df['description'].tolist(),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# PASO 2: Codificar imágenes\n",
        "image_embeddings, valid_img_indices, failed_img_indices = encode_images(\n",
        "    products_df['image'].tolist(),\n",
        "    batch_size=16,\n",
        "    timeout=5\n",
        ")\n",
        "\n",
        "# PASO 3: Combinar embeddings\n",
        "# Estrategia 1: Promedio simple (50-50)\n",
        "combined_embeddings = combine_embeddings(\n",
        "    text_embeddings,\n",
        "    image_embeddings,\n",
        "    text_weight=0.5,\n",
        "    image_weight=0.5\n",
        ")\n",
        "\n",
        "# ALTERNATIVA: Pesar más el texto (mejor para queries textuales)\n",
        "# combined_embeddings = combine_embeddings(\n",
        "#     text_embeddings,\n",
        "#     image_embeddings,\n",
        "#     text_weight=0.7,\n",
        "#     image_weight=0.3\n",
        "# )\n",
        "\n",
        "# PASO 4: Crear índice vectorial\n",
        "collection = create_vector_index(\n",
        "    combined_embeddings,\n",
        "    products_df,\n",
        "    collection_name=\"products\"\n",
        ")\n",
        "\n",
        "# ==================== ANÁLISIS DEL ESPACIO VECTORIAL ====================\n",
        "print(\"\\nANÁLISIS DEL ESPACIO VECTORIAL\")\n",
        "\n",
        "# Calcular similitud promedio entre productos\n",
        "sample_size = min(100, len(combined_embeddings))\n",
        "sample_embeddings = combined_embeddings[:sample_size]\n",
        "\n",
        "# Matriz de similitudes (100x100)\n",
        "similarity_matrix = np.dot(sample_embeddings, sample_embeddings.T)\n",
        "\n",
        "# Estadísticas\n",
        "avg_similarity = (similarity_matrix.sum() - sample_size) / (sample_size * (sample_size - 1))\n",
        "max_similarity = similarity_matrix[np.triu_indices(sample_size, k=1)].max()\n",
        "min_similarity = similarity_matrix[np.triu_indices(sample_size, k=1)].min()\n",
        "\n",
        "print(f\"\\n Similitud entre productos (muestra de {sample_size}):\")\n",
        "print(f\"   • Promedio: {avg_similarity:.4f}\")\n",
        "print(f\"   • Máxima: {max_similarity:.4f}\")\n",
        "print(f\"   • Mínima: {min_similarity:.4f}\")\n",
        "print(f\"   • Rango: {max_similarity - min_similarity:.4f}\")\n",
        "\n",
        "# Interpretación\n",
        "if avg_similarity > 0.7:\n",
        "    print(f\"  Espacio vectorial muy denso (posible colapso semántico)\")\n",
        "elif avg_similarity < 0.3:\n",
        "    print(f\"  Buena separación semántica entre productos\")\n",
        "else:\n",
        "    print(f\"   Separación moderada (esperado para productos similares)\")\n",
        "\n",
        "print(\"\\nINDEXACIÓN COMPLETADA\")\n",
        "print(f\"Sistema listo para búsquedas multimodales\")\n",
        "print(f\"   • Productos indexados: {len(products_df):,}\")\n",
        "print(f\"   • Embeddings: texto + imagen (512 dims)\")\n",
        "print(f\"   • Base de datos: ChromaDB con HNSW\")\n",
        "print(f\"   • Búsquedas soportadas: texto→productos, imagen→productos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LkfPQ-JldTv",
        "outputId": "52de8635-6d70-4996-e043-cb9b7c1c6e43"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CODIFICACIÓN E INDEXACIÓN MULTIMODAL\n",
            "\n",
            "Codificar 69 descripciones de texto\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Texto: 100%|██████████| 3/3 [00:00<00:00, 30.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Embeddings de texto: (69, 512)\n",
            "   Norma promedio: 1.0000\n",
            "\n",
            "Codificar 69 imágenes de productos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Imágenes:   7%|▋         | 5/69 [00:00<00:05, 11.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Error en imagen 2: cannot identify image file <_io.BytesIO object at 0x7e4eba30\n",
            " Error en imagen 3: HTTPSConnectionPool(host='www.barcodable.com', port=443): Ma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Imágenes:  26%|██▌       | 18/69 [00:01<00:04, 12.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Error en imagen 15: cannot identify image file <_io.BytesIO object at 0x7e4eb9d6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Imágenes:  43%|████▎     | 30/69 [00:02<00:02, 17.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Error en imagen 28: HTTPSConnectionPool(host='www.barcodable.com', port=443): Ma\n",
            " Error en imagen 30: HTTPSConnectionPool(host='www.barcodable.com', port=443): Ma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Imágenes: 100%|██████████| 69/69 [00:05<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Error en imagen 66: cannot identify image file <_io.BytesIO object at 0x7e4eb9c5\n",
            "\n",
            " Embeddings de imágenes: (69, 512)\n",
            "   Imágenes exitosas: 58 (84.1%)\n",
            "   Imágenes fallidas: 11\n",
            "   Norma promedio: 0.8406\n",
            "\n",
            "Combinar embeddings (texto: 0.5, imagen: 0.5)...\n",
            "   Embeddings combinados: (69, 512)\n",
            "   Norma promedio: 1.0000\n",
            "\n",
            "Crear índice vectorial 'products'\n",
            "Colección existente eliminada\n",
            "Colección creada con HNSW (similitud coseno)\n",
            " Agregar 69 productos al índice\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Indexando: 100%|██████████| 1/1 [00:00<00:00, 18.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   Índice creado exitosamente\n",
            "   Total productos indexados: 69\n",
            "\n",
            "ÍNDICE:\n",
            "   • Dimensión de embeddings: 512\n",
            "   • Algoritmo: HNSW (Approximate Nearest Neighbors)\n",
            "   • Métrica de similitud: Coseno\n",
            "   • Complejidad búsqueda: O(log n)\n",
            "   • Memoria estimada: 0.13 MB\n",
            "\n",
            "ANÁLISIS DEL ESPACIO VECTORIAL\n",
            "\n",
            " Similitud entre productos (muestra de 69):\n",
            "   • Promedio: 0.6163\n",
            "   • Máxima: 0.9866\n",
            "   • Mínima: 0.2314\n",
            "   • Rango: 0.7552\n",
            "   Separación moderada (esperado para productos similares)\n",
            "\n",
            "INDEXACIÓN COMPLETADA\n",
            "Sistema listo para búsquedas multimodales\n",
            "   • Productos indexados: 69\n",
            "   • Embeddings: texto + imagen (512 dims)\n",
            "   • Base de datos: ChromaDB con HNSW\n",
            "   • Búsquedas soportadas: texto→productos, imagen→productos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: Buscar productos similares a \"wireless headphones\"\n",
        "test_query = \"wireless bluetooth headphones\"\n",
        "tokens = clip.tokenize([test_query]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    query_embedding = model.encode_text(tokens)\n",
        "    query_embedding /= query_embedding.norm(dim=-1, keepdim=True)\n",
        "\n",
        "# Buscar en ChromaDB\n",
        "results = collection.query(\n",
        "    query_embeddings=query_embedding.cpu().numpy().tolist(),\n",
        "    n_results=5\n",
        ")\n",
        "\n",
        "print(\"\\nTest de búsqueda: 'wireless bluetooth headphones'\")\n",
        "for i, (name, distance) in enumerate(zip(\n",
        "    results['metadatas'][0],\n",
        "    results['distances'][0]\n",
        "), 1):\n",
        "    similarity = 1 - distance  # ChromaDB retorna distancias\n",
        "    print(f\"{i}. {name['name'][:60]} (sim: {similarity:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKXfLGQqqTqM",
        "outputId": "beb4a767-1c78-4d07-d2e0-9ae34eb31f46"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test de búsqueda: 'wireless bluetooth headphones'\n",
            "1. Certified Refurbished Amazon Fire TV with Alexa Voice Remote (sim: 0.571)\n",
            "2. Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker (sim: 0.549)\n",
            "3. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Inclu (sim: 0.548)\n",
            "4. Kindle E-reader - White, 6 Glare-Free Touchscreen Display, W (sim: 0.541)\n",
            "5. Amazon Echo (1st Generationcertified) Color:White Free Shipp (sim: 0.539)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poca RAM:\n",
        "1. Reducir batch_size\n",
        "text_embeddings = encode_texts(texts, batch_size=16)  # vs 32\n",
        "2. Procesar imágenes en CPU (más lento pero menos VRAM)\n",
        "model_cpu = model.cpu()\n",
        "3. Usar precisión float16 (mitad de memoria)\n",
        "text_embeddings = text_embeddings.astype(np.float16)\n",
        "\n"
      ],
      "metadata": {
        "id": "52WGd_m7q0mc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX3FyrYj2as5"
      },
      "source": [
        "## 6. Búsqueda Multimodal (Retrieval Inicial)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementación de las funcionalidades de búsqueda text-to-product e image-to-product. Se recupera un conjunto inicial (top-k) de productos candidatos, mostrando información básica como imagen, título y categoría"
      ],
      "metadata": {
        "id": "1jyLcjkijOQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BÚSQUEDA TEXTO → PRODUCTOS\n",
        "---\n",
        "    Búsqueda de productos usando consulta textual.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UXhIHzMUvU7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_by_text(query, collection, top_k=20, return_scores=True):\n",
        "    \"\"\"\n",
        "    Búsqueda de productos usando consulta textual.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    query : str\n",
        "        Consulta textual del usuario (ej: \"wireless headphones\")\n",
        "    collection : chromadb.Collection\n",
        "        Colección de ChromaDB con productos indexados\n",
        "    top_k : int\n",
        "        Número de resultados a retornar\n",
        "    return_scores : bool\n",
        "        Si True, incluye scores de similitud\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    dict\n",
        "        Resultados con 'documents', 'metadatas', 'distances', 'ids'\n",
        "    \"\"\"\n",
        "    print(f\"\\nBúsqueda por texto: '{query}'\")\n",
        "\n",
        "    # PASO 1: Codificar query de texto con CLIP\n",
        "    # tokenize() convierte texto a tokens que CLIP entiende\n",
        "    # truncate=True: corta si excede 77 tokens\n",
        "    tokens = clip.tokenize([query], truncate=True).to(device)\n",
        "\n",
        "    # PASO 2: Generar embedding del query\n",
        "    with torch.no_grad():\n",
        "        # encode_text() retorna vector de 512 dimensiones\n",
        "        query_embedding = model.encode_text(tokens)\n",
        "\n",
        "        # CRÍTICO: Normalizar para similitud coseno\n",
        "        # Sin esto, las distancias no son comparables\n",
        "        query_embedding /= query_embedding.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # PASO 3: Buscar en el índice vectorial\n",
        "    # ChromaDB usa HNSW para búsqueda aproximada O(log n)\n",
        "    # query_embeddings debe ser lista de listas: [[emb1], [emb2], ...]\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding.cpu().numpy().tolist(),\n",
        "        n_results=top_k,\n",
        "        include=['documents', 'metadatas', 'distances']\n",
        "    )\n",
        "\n",
        "    # PASO 4: Convertir distancias a scores de similitud\n",
        "    # ChromaDB retorna distancias coseno (0 = idéntico, 2 = opuesto)\n",
        "    # Convertimos a similitud (1 = idéntico, -1 = opuesto)\n",
        "    if return_scores:\n",
        "        similarities = [1 - dist for dist in results['distances'][0]]\n",
        "        results['similarities'] = [similarities]\n",
        "\n",
        "        # Estadísticas de la búsqueda\n",
        "        avg_sim = np.mean(similarities)\n",
        "        max_sim = np.max(similarities)\n",
        "        min_sim = np.min(similarities)\n",
        "\n",
        "        print(f\"   Resultados encontrados: {len(results['metadatas'][0])}\")\n",
        "        print(f\"   Similitud promedio: {avg_sim:.3f}\")\n",
        "        print(f\"   Similitud máxima: {max_sim:.3f}\")\n",
        "        print(f\"   Similitud mínima: {min_sim:.3f}\")\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "cn--kUiIvUG7"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Búsqueda de productos usando imagen de referencia"
      ],
      "metadata": {
        "id": "E3rLPJhTvtRL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "-FiV6W_x2as5"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "\n",
        "def search_by_image(image_input, collection, top_k=20, return_scores=True):\n",
        "    \"\"\"\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    image_input : str or PIL.Image\n",
        "        Ruta a imagen, URL, o imagen PIL cargada\n",
        "    collection : chromadb.Collection\n",
        "        Colección de ChromaDB con productos indexados\n",
        "    top_k : int\n",
        "        Número de resultados a retornar\n",
        "    return_scores : bool\n",
        "        Si True, incluye scores de similitud\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    dict or None\n",
        "        Resultados con 'documents', 'metadatas', 'distances', 'ids'\n",
        "        None si falla la carga de la imagen\n",
        "    \"\"\"\n",
        "    print(f\"   Buscar top-{top_k} productos similares\")\n",
        "\n",
        "    # PASO 1: Cargar imagen con manejo robusto de errores\n",
        "    try:\n",
        "        if isinstance(image_input, str):\n",
        "            # Caso 1: URL de imagen\n",
        "            if image_input.startswith('http'):\n",
        "                print(f\"Descargar imagen desde URL\")\n",
        "\n",
        "                # Headers para simular navegador (evitar bloqueos)\n",
        "                headers = {\n",
        "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "                }\n",
        "\n",
        "                response = requests.get(\n",
        "                    image_input,\n",
        "                    timeout=10,\n",
        "                    headers=headers,\n",
        "                    verify=False  # Ignorar SSL errors\n",
        "                )\n",
        "\n",
        "                # Verificar que sea una imagen válida\n",
        "                if response.status_code != 200:\n",
        "                    raise ValueError(f\"HTTP {response.status_code}: No se pudo descargar la imagen\")\n",
        "\n",
        "                # Verificar content-type\n",
        "                content_type = response.headers.get('content-type', '')\n",
        "                if 'image' not in content_type.lower():\n",
        "                    print(f\" Advertencia: Content-Type es '{content_type}', esperaba 'image/*'\")\n",
        "\n",
        "                # Intentar abrir la imagen\n",
        "                image_bytes = BytesIO(response.content)\n",
        "                image = Image.open(image_bytes).convert('RGB')\n",
        "\n",
        "            # Caso 2: Ruta local\n",
        "            elif os.path.exists(image_input):\n",
        "                print(f\"Cargar imagen desde archivo local\")\n",
        "                image = Image.open(image_input).convert('RGB')\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Imagen no encontrada: {image_input}\")\n",
        "\n",
        "        # Caso 3: Objeto PIL.Image ya cargado\n",
        "        elif isinstance(image_input, Image.Image):\n",
        "            image = image_input.convert('RGB')\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Tipo de input no soportado: {type(image_input)}\")\n",
        "\n",
        "        # Verificar tamaño mínimo (evitar imágenes corruptas de 1x1)\n",
        "        if image.size[0] < 10 or image.size[1] < 10:\n",
        "            raise ValueError(f\"Imagen muy pequeña: {image.size}\")\n",
        "\n",
        "        print(f\" Imagen cargada exitosamente: {image.size}\")\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Timeout: La imagen tardó demasiado en descargar\")\n",
        "        return None\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error de red: {str(e)[:100]}\")\n",
        "        return None\n",
        "\n",
        "    except Image.UnidentifiedImageError:\n",
        "        print(f\"    Error: No se pudo identificar el formato de la imagen\")\n",
        "        print(f\"    La URL puede no contener una imagen válida\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    Error inesperado al cargar imagen: {str(e)[:100]}\")\n",
        "        return None\n",
        "\n",
        "    # PASO 2: Preprocesar imagen para CLIP\n",
        "    try:\n",
        "        image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "    except Exception as e:\n",
        "        print(f\"    Error al preprocesar imagen: {e}\")\n",
        "        return None\n",
        "\n",
        "    # PASO 3: Generar embedding de la imagen\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            query_embedding = model.encode_image(image_tensor)\n",
        "            query_embedding /= query_embedding.norm(dim=-1, keepdim=True)\n",
        "    except Exception as e:\n",
        "        print(f\"    Error al generar embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "    # PASO 4: Buscar en el índice vectorial\n",
        "    try:\n",
        "        results = collection.query(\n",
        "            query_embeddings=query_embedding.cpu().numpy().tolist(),\n",
        "            n_results=top_k,\n",
        "            include=['documents', 'metadatas', 'distances']\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"    Error al buscar en el índice: {e}\")\n",
        "        return None\n",
        "\n",
        "    # PASO 5: Convertir distancias a similitudes\n",
        "    if return_scores and results:\n",
        "        similarities = [1 - dist for dist in results['distances'][0]]\n",
        "        results['similarities'] = [similarities]\n",
        "\n",
        "        avg_sim = np.mean(similarities)\n",
        "        max_sim = np.max(similarities)\n",
        "\n",
        "        print(f\"    Resultados encontrados: {len(results['metadatas'][0])}\")\n",
        "        print(f\"    Similitud promedio: {avg_sim:.3f}\")\n",
        "        print(f\"    Similitud máxima: {max_sim:.3f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Búsqueda híbrida combinando texto e imagen"
      ],
      "metadata": {
        "id": "xLgYHF7swQqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_multimodal(text_query=None, image_input=None, collection=None,\n",
        "                     top_k=20, text_weight=0.6, image_weight=0.4):\n",
        "    \"\"\"\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    text_query : str, optional\n",
        "        Consulta textual\n",
        "    image_input : str or PIL.Image, optional\n",
        "        Imagen de referencia\n",
        "    collection : chromadb.Collection\n",
        "        Colección de ChromaDB\n",
        "    top_k : int\n",
        "        Número de resultados\n",
        "    text_weight : float\n",
        "        Peso del componente textual (0-1)\n",
        "    image_weight : float\n",
        "        Peso del componente visual (0-1)\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    dict\n",
        "        Resultados combinados\n",
        "    \"\"\"\n",
        "    print(f\"\\nBúsqueda multimodal híbrida\")\n",
        "    print(f\"   Pesos: Texto={text_weight}, Imagen={image_weight}\")\n",
        "\n",
        "    embeddings_to_combine = []\n",
        "\n",
        "    # PASO 1: Codificar texto si se proporciona\n",
        "    if text_query:\n",
        "        print(f\"   Procesar query de texto: '{text_query}'\")\n",
        "        try:\n",
        "            tokens = clip.tokenize([text_query], truncate=True).to(device)\n",
        "            with torch.no_grad():\n",
        "                text_emb = model.encode_text(tokens)\n",
        "                text_emb /= text_emb.norm(dim=-1, keepdim=True)\n",
        "            embeddings_to_combine.append((text_emb, text_weight))\n",
        "            print(f\"   Embedding de texto generado\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Error al procesar texto: {e}\")\n",
        "\n",
        "    # PASO 2: Codificar imagen si se proporciona\n",
        "    if image_input:\n",
        "        print(f\"    Procesar imagen de referencia\")\n",
        "\n",
        "        try:\n",
        "            # Cargar imagen con manejo de errores\n",
        "            if isinstance(image_input, str):\n",
        "                if image_input.startswith('http'):\n",
        "                    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "                    response = requests.get(image_input, timeout=10, headers=headers, verify=False)\n",
        "\n",
        "                    if response.status_code != 200:\n",
        "                        raise ValueError(f\"HTTP {response.status_code}\")\n",
        "\n",
        "                    image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "                else:\n",
        "                    image = Image.open(image_input).convert('RGB')\n",
        "            else:\n",
        "                image = image_input.convert('RGB')\n",
        "\n",
        "            # Verificar tamaño\n",
        "            if image.size[0] < 10 or image.size[1] < 10:\n",
        "                raise ValueError(f\"Imagen muy pequeña: {image.size}\")\n",
        "\n",
        "            # Codificar\n",
        "            image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                image_emb = model.encode_image(image_tensor)\n",
        "                image_emb /= image_emb.norm(dim=-1, keepdim=True)\n",
        "            embeddings_to_combine.append((image_emb, image_weight))\n",
        "            print(f\"    Embedding de imagen generado\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"     No se pudo procesar la imagen: {str(e)[:100]}\")\n",
        "            print(f\"    Continuando solo con búsqueda por texto...\")\n",
        "\n",
        "    # PASO 3: Verificar que tengamos al menos un embedding\n",
        "    if not embeddings_to_combine:\n",
        "        raise ValueError(\"No se pudo generar ningún embedding (texto ni imagen)\")\n",
        "\n",
        "    # PASO 4: Combinar embeddings con pesos\n",
        "    if len(embeddings_to_combine) == 1:\n",
        "        # Solo tenemos un tipo de embedding\n",
        "        combined_emb = embeddings_to_combine[0][0]\n",
        "        print(f\"    Usando solo {'texto' if text_query else 'imagen'}\")\n",
        "    else:\n",
        "        # Combinar ambos\n",
        "        combined_emb = sum(emb * weight for emb, weight in embeddings_to_combine)\n",
        "        # Re-normalizar después de combinar\n",
        "        combined_emb /= combined_emb.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # PASO 5: Buscar en el índice\n",
        "    results = collection.query(\n",
        "        query_embeddings=combined_emb.cpu().numpy().tolist(),\n",
        "        n_results=top_k,\n",
        "        include=['documents', 'metadatas', 'distances']\n",
        "    )\n",
        "\n",
        "    # Agregar similitudes\n",
        "    similarities = [1 - dist for dist in results['distances'][0]]\n",
        "    results['similarities'] = [similarities]\n",
        "\n",
        "    print(f\"    Búsqueda completada: {len(results['metadatas'][0])} resultados\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "bHr3XDh5wNpD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encuentra una URL de imagen válida en el dataset."
      ],
      "metadata": {
        "id": "jVBIo8qGwlEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_valid_image_url(df, category_filter=None, max_attempts=10):\n",
        "    \"\"\"\n",
        "    Encuentra una URL de imagen válida en el dataset.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame de productos\n",
        "    category_filter : str, optional\n",
        "        Filtrar por categoría (ej: \"Computer\", \"Electronics\")\n",
        "    max_attempts : int\n",
        "        Número máximo de intentos\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    str or None\n",
        "        URL de imagen válida, o None si no se encuentra\n",
        "    \"\"\"\n",
        "    print(f\"\\nBuscar imagen válida en el dataset\")\n",
        "\n",
        "    # Filtrar por categoría si se especifica\n",
        "    if category_filter:\n",
        "        df_filtered = df[df['main_category'].str.contains(category_filter, case=False, na=False)]\n",
        "        if len(df_filtered) == 0:\n",
        "            print(f\"   No se encontraron productos en categoría '{category_filter}'\")\n",
        "            df_filtered = df\n",
        "    else:\n",
        "        df_filtered = df\n",
        "\n",
        "    # Intentar cargar imágenes hasta encontrar una válida\n",
        "    for attempt in range(min(max_attempts, len(df_filtered))):\n",
        "        row = df_filtered.iloc[attempt]\n",
        "        image_url = row['image']\n",
        "\n",
        "        try:\n",
        "            # Intentar descargar y abrir\n",
        "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "            response = requests.get(image_url, timeout=5, headers=headers, verify=False)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "\n",
        "                # Verificar tamaño\n",
        "                if image.size[0] >= 10 and image.size[1] >= 10:\n",
        "                    print(f\"    Imagen válida encontrada: {row['name'][:50]}...\")\n",
        "                    print(f\"    URL: {image_url[:80]}...\")\n",
        "                    return image_url\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    print(f\"    No se encontró ninguna imagen válida después de {max_attempts} intentos\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "FQL1ASNZwi_j"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Función de visualización"
      ],
      "metadata": {
        "id": "PyE7rGakxVWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(results, top_n=10, show_details=True):\n",
        "    \"\"\"\n",
        "    Muestra resultados de búsqueda de forma legible.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    results : dict\n",
        "        Resultados de búsqueda\n",
        "    top_n : int\n",
        "        Número de resultados a mostrar\n",
        "    show_details : bool\n",
        "        Si True, muestra detalles adicionales\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TOP {top_n} RESULTADOS\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    metadatas = results['metadatas'][0][:top_n]\n",
        "    similarities = results.get('similarities', [[]])[0][:top_n]\n",
        "\n",
        "    for i, (meta, sim) in enumerate(zip(metadatas, similarities), 1):\n",
        "        # Encabezado del producto\n",
        "        print(f\"[{i}] {meta['name'][:70]}\")\n",
        "\n",
        "        # Barra de similitud visual\n",
        "        sim_percentage = int(sim * 100)\n",
        "        bar_length = 30\n",
        "        filled = int(bar_length * sim)\n",
        "        bar = '█' * filled + '░' * (bar_length - filled)\n",
        "        print(f\"    Similitud: {bar} {sim:.3f} ({sim_percentage}%)\")\n",
        "\n",
        "        # Detalles adicionales\n",
        "        if show_details:\n",
        "            print(f\"     Marca: {meta['brand']}\")\n",
        "            print(f\"     Categoría: {meta['category']}\")\n",
        "            print(f\"     Precio: {meta['price']}\")\n",
        "            print(f\"     Rating: {meta['avg_rating']:.1f}/5.0 ({meta['num_reviews']} reviews)\")\n",
        "            print(f\"     Imagen: {meta['image'][:60]}...\")\n",
        "\n",
        "        print()\n",
        "\n"
      ],
      "metadata": {
        "id": "VC-kyfybxZeb"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### DEMOSTRACIÓN DE BÚSQUEDA MULTIMODAL"
      ],
      "metadata": {
        "id": "MpGvlJ1Nw3G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EJEMPLO 1: Búsqueda por texto (siempre funciona)\n",
        "print(\"\\nEJEMPLO 1: Búsqueda por texto\")\n",
        "\n",
        "query = \"wireless bluetooth headphones noise canceling\"\n",
        "results_text = search_by_text(query, collection, top_k=10)\n",
        "if results_text:\n",
        "    display_results(results_text, top_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mleb2Er1wxij",
        "outputId": "09d73fc6-4dd2-43c1-b3ee-667fed8e178f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EJEMPLO 1: Búsqueda por texto\n",
            "\n",
            "Búsqueda por texto: 'wireless bluetooth headphones noise canceling'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.552\n",
            "   Similitud máxima: 0.594\n",
            "   Similitud mínima: 0.533\n",
            "\n",
            "================================================================================\n",
            "TOP 5 RESULTADOS\n",
            "================================================================================\n",
            "\n",
            "[1] Certified Refurbished Amazon Fire TV with Alexa Voice Remote\n",
            "    Similitud: █████████████████░░░░░░░░░░░░░ 0.594 (59%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Amazon SMP\n",
            "     Precio: $44\n",
            "     Rating: 2.8/5.0 (5 reviews)\n",
            "     Imagen: https://www.upccodesearch.com/images/barcode/0848719063264.p...\n",
            "\n",
            "[2] All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Specia\n",
            "    Similitud: ████████████████░░░░░░░░░░░░░░ 0.559 (55%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Fire Tablets\n",
            "     Precio: $118\n",
            "     Rating: 4.6/5.0 (112 reviews)\n",
            "     Imagen: https://www.upccodesearch.com/images/barcode/0841667105758.p...\n",
            "\n",
            "[3] Kindle E-reader - White, 6 Glare-Free Touchscreen Display, Wi-Fi - Inc\n",
            "    Similitud: ████████████████░░░░░░░░░░░░░░ 0.554 (55%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Office\n",
            "     Precio: $163\n",
            "     Rating: 4.5/5.0 (427 reviews)\n",
            "     Imagen: https://www.barcodable.com/images/barcode/0841667100418.png...\n",
            "\n",
            "[4] Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker\n",
            "    Similitud: ████████████████░░░░░░░░░░░░░░ 0.551 (55%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Amazon Echo\n",
            "     Precio: $115\n",
            "     Rating: 4.5/5.0 (826 reviews)\n",
            "     Imagen: https://pisces.bbystatic.com/image2/BestBuy_US/images/produc...\n",
            "\n",
            "[5] Oem Amazon Kindle Power Usb Adapter Wall Travel Charger Fire/dx/+micro\n",
            "    Similitud: ████████████████░░░░░░░░░░░░░░ 0.550 (55%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Tablet & eBook Reader Accs\n",
            "     Precio: $147\n",
            "     Rating: 1.0/5.0 (4 reviews)\n",
            "     Imagen: https://i.ebayimg.com/thumbs/images/g/EX4AAOSw3GVbSwQN/s-l96...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EJEMPLO 2: Búsqueda por imagen (con validación)\n",
        "print(\"\\nEJEMPLO 2: Búsqueda por imagen\")\n",
        "\n",
        "# Buscar una imagen válida\n",
        "valid_image_url = get_valid_image_url(products_df, max_attempts=20)\n",
        "\n",
        "if valid_image_url:\n",
        "    results_image = search_by_image(valid_image_url, collection, top_k=10)\n",
        "    if results_image:\n",
        "        display_results(results_image, top_n=5)\n",
        "else:\n",
        "    print(\"  Saltando ejemplo de búsqueda por imagen (no hay imágenes válidas)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JXI2gvCxPgK",
        "outputId": "c4f941fb-7e60-4612-f486-198aacbffd2d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EJEMPLO 2: Búsqueda por imagen\n",
            "\n",
            "Buscar imagen válida en el dataset\n",
            "    Imagen válida encontrada: AmazonBasics AAA Performance Alkaline Batteries (3...\n",
            "    URL: https://images-na.ssl-images-amazon.com/images/I/81qmNyJo%2BkL._SL1500_.jpg...\n",
            "   Buscar top-10 productos similares\n",
            "Descargar imagen desde URL\n",
            " Imagen cargada exitosamente: (1500, 893)\n",
            "    Resultados encontrados: 10\n",
            "    Similitud promedio: 0.608\n",
            "    Similitud máxima: 0.818\n",
            "\n",
            "================================================================================\n",
            "TOP 5 RESULTADOS\n",
            "================================================================================\n",
            "\n",
            "[1] AmazonBasics AAA Performance Alkaline Batteries (36 Count)\n",
            "    Similitud: ████████████████████████░░░░░░ 0.818 (81%)\n",
            "     Marca: Amazonbasics\n",
            "     Categoría: AA\n",
            "     Precio: $128\n",
            "     Rating: 4.5/5.0 (8343 reviews)\n",
            "     Imagen: https://images-na.ssl-images-amazon.com/images/I/81qmNyJo%2B...\n",
            "\n",
            "[2] AmazonBasics AA Performance Alkaline Batteries (48 Count) - Packaging \n",
            "    Similitud: ████████████████████░░░░░░░░░░ 0.691 (69%)\n",
            "     Marca: Amazonbasics\n",
            "     Categoría: AA\n",
            "     Precio: $46\n",
            "     Rating: 4.5/5.0 (3728 reviews)\n",
            "     Imagen: https://images-na.ssl-images-amazon.com/images/I/812VtLZldxL...\n",
            "\n",
            "[3] All-New Fire HD 8 Tablet with Alexa, 8 HD Display, 16 GB, Marine Blue \n",
            "    Similitud: █████████████████░░░░░░░░░░░░░ 0.583 (58%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Fire Tablets\n",
            "     Precio: $171\n",
            "     Rating: 4.6/5.0 (883 reviews)\n",
            "     Imagen: https://pisces.bbystatic.com/image2/BestBuy_US/images/produc...\n",
            "\n",
            "[4] Amazon 9W PowerFast Official OEM USB Charger and Power Adapter for Fir\n",
            "    Similitud: █████████████████░░░░░░░░░░░░░ 0.577 (57%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Computers & Accessories\n",
            "     Precio: $532\n",
            "     Rating: 4.7/5.0 (61 reviews)\n",
            "     Imagen: https://images-na.ssl-images-amazon.com/images/I/81zEmhwJU7L...\n",
            "\n",
            "[5] AmazonBasics 11.6-Inch Laptop Sleeve\n",
            "    Similitud: █████████████████░░░░░░░░░░░░░ 0.577 (57%)\n",
            "     Marca: Amazonbasics\n",
            "     Categoría: Portable Computer Accessories\n",
            "     Precio: $146\n",
            "     Rating: 4.0/5.0 (6 reviews)\n",
            "     Imagen: https://images-na.ssl-images-amazon.com/images/I/81xGoFGB49L...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EJEMPLO 3: Búsqueda híbrida (con fallback)\n",
        "print(\"\\n EJEMPLO 3: Búsqueda híbrida (texto + imagen)\")\n",
        "\n",
        "query_text = \"gaming laptop high performance\"\n",
        "\n",
        "# Buscar imagen de laptop válida\n",
        "laptop_image_url = get_valid_image_url(products_df, category_filter=\"Computer\", max_attempts=10)\n",
        "\n",
        "if laptop_image_url:\n",
        "    results_hybrid = search_multimodal(\n",
        "        text_query=query_text,\n",
        "        image_input=laptop_image_url,\n",
        "        collection=collection,\n",
        "        top_k=10,\n",
        "        text_weight=0.7,  # Más peso al texto (más robusto)\n",
        "        image_weight=0.3\n",
        "    )\n",
        "    if results_hybrid:\n",
        "        display_results(results_hybrid, top_n=5)\n",
        "else:\n",
        "    print(\"    No se encontró imagen válida, usando solo texto...\")\n",
        "    results_hybrid = search_by_text(query_text, collection, top_k=10)\n",
        "    if results_hybrid:\n",
        "        display_results(results_hybrid, top_n=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04i7aCnfx1Db",
        "outputId": "d127ccc0-a340-46f7-d583-8ec04d4c5904"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EJEMPLO 3: Búsqueda híbrida (texto + imagen)\n",
            "\n",
            "Buscar imagen válida en el dataset\n",
            "    Imagen válida encontrada: Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB,...\n",
            "    URL: https://pisces.bbystatic.com/image2/BestBuy_US/images/products/5026/5026000_sd.j...\n",
            "\n",
            "Búsqueda multimodal híbrida\n",
            "   Pesos: Texto=0.7, Imagen=0.3\n",
            "   Procesar query de texto: 'gaming laptop high performance'\n",
            "   Embedding de texto generado\n",
            "    Procesar imagen de referencia\n",
            "    Embedding de imagen generado\n",
            "    Búsqueda completada: 10 resultados\n",
            "\n",
            "================================================================================\n",
            "TOP 5 RESULTADOS\n",
            "================================================================================\n",
            "\n",
            "[1] Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Blue Kid-Proof Case\n",
            "    Similitud: ██████████████████████░░░░░░░░ 0.762 (76%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Computers\n",
            "     Precio: $783\n",
            "     Rating: 4.5/5.0 (1986 reviews)\n",
            "     Imagen: https://pisces.bbystatic.com/image2/BestBuy_US/images/produc...\n",
            "\n",
            "[2] Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offers, Black\n",
            "    Similitud: █████████████████████░░░░░░░░░ 0.731 (73%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Fire Tablets\n",
            "     Precio: $56\n",
            "     Rating: 4.5/5.0 (1395 reviews)\n",
            "     Imagen: https://pisces.bbystatic.com/image2/BestBuy_US/images/produc...\n",
            "\n",
            "[3] Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Pink Kid-Proof Case\n",
            "    Similitud: █████████████████████░░░░░░░░░ 0.703 (70%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Fire Tablets\n",
            "     Precio: $27\n",
            "     Rating: 4.5/5.0 (1676 reviews)\n",
            "     Imagen: https://pisces.bbystatic.com/image2/BestBuy_US/images/produc...\n",
            "\n",
            "[4] All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 32 GB - Includes Specia\n",
            "    Similitud: █████████████████████░░░░░░░░░ 0.701 (70%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Fire Tablets\n",
            "     Precio: $59\n",
            "     Rating: 4.5/5.0 (223 reviews)\n",
            "     Imagen: https://pisces.bbystatic.com/image2/BestBuy_US/images/produc...\n",
            "\n",
            "[5] All-New Fire HD 8 Kids Edition Tablet, 8 HD Display, 32 GB, Blue Kid-P\n",
            "    Similitud: ████████████████████░░░░░░░░░░ 0.693 (69%)\n",
            "     Marca: Amazon\n",
            "     Categoría: Fire Tablets\n",
            "     Precio: $124\n",
            "     Rating: 4.6/5.0 (233 reviews)\n",
            "     Imagen: https://c1.neweggimages.com/NeweggImage/ProductImage/A22F_1_...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### COMPARACIÓN DE MÉTODOS DE BÚSQUEDA"
      ],
      "metadata": {
        "id": "QBBwBXbVyCZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_search_methods(query_text, query_image=None, collection=None, top_k=5):\n",
        "    \"\"\"\n",
        "    Compara resultados de diferentes métodos de búsqueda.\n",
        "    \"\"\"\n",
        "\n",
        "    # Método 1: Solo texto\n",
        "    print(f\"\\n MÉTODO 1: Solo Texto\")\n",
        "    results_text = search_by_text(query_text, collection, top_k=top_k)\n",
        "    display_results(results_text, top_n=top_k, show_details=False)\n",
        "\n",
        "    # Método 2: Solo imagen (si se proporciona)\n",
        "    if query_image:\n",
        "        print(f\"\\n  MÉTODO 2: Solo Imagen\")\n",
        "        results_image = search_by_image(query_image, collection, top_k=top_k)\n",
        "        display_results(results_image, top_n=top_k, show_details=False)\n",
        "\n",
        "        # Método 3: Híbrido\n",
        "        print(f\"\\n MÉTODO 3: Híbrido (60% texto, 40% imagen)\")\n",
        "        results_hybrid = search_multimodal(\n",
        "            text_query=query_text,\n",
        "            image_input=query_image,\n",
        "            collection=collection,\n",
        "            top_k=top_k,\n",
        "            text_weight=0.6,\n",
        "            image_weight=0.4\n",
        "        )\n",
        "        display_results(results_hybrid, top_n=top_k, show_details=False)\n"
      ],
      "metadata": {
        "id": "mADjwOjEyAAL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Análisis de calidad de búsqueda"
      ],
      "metadata": {
        "id": "ftbDee8qzeTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_search_quality(query, results, expected_category=None):\n",
        "    \"\"\"\n",
        "    Analiza la calidad de los resultados de búsqueda.\n",
        "    \"\"\"\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"\\nMétricas de calidad:\")\n",
        "\n",
        "    # Similitud promedio\n",
        "    sims = results['similarities'][0]\n",
        "    print(f\"   • Similitud promedio: {np.mean(sims):.3f}\")\n",
        "    print(f\"   • Similitud std: {np.std(sims):.3f}\")\n",
        "    print(f\"   • Rango: [{np.min(sims):.3f}, {np.max(sims):.3f}]\")\n",
        "\n",
        "    # Diversidad de categorías\n",
        "    categories = [m['category'] for m in results['metadatas'][0]]\n",
        "    unique_cats = len(set(categories))\n",
        "    print(f\"   • Categorías únicas: {unique_cats}/{len(categories)}\")\n",
        "\n",
        "    # Precisión de categoría (si se espera alguna)\n",
        "    if expected_category:\n",
        "        matches = sum(1 for cat in categories[:5] if expected_category.lower() in cat.lower())\n",
        "        precision = matches / 5\n",
        "        print(f\"   • Precisión@5 (categoría '{expected_category}'): {precision:.2%}\")\n",
        "\n",
        "    # Distribución de ratings\n",
        "    ratings = [m['avg_rating'] for m in results['metadatas'][0]]\n",
        "    print(f\"   • Rating promedio: {np.mean(ratings):.2f}/5.0\")\n",
        "\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "id": "iYX28TLUzZhE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analizar búsqueda de headphones\n",
        "analyze_search_quality(\n",
        "    \"wireless bluetooth headphones\",\n",
        "    results_text,\n",
        "    expected_category=\"Electronics\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXzS3D58znzT",
        "outputId": "6e485770-0e52-477b-d85a-bea837c1bbac"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'wireless bluetooth headphones'\n",
            "\n",
            "Métricas de calidad:\n",
            "   • Similitud promedio: 0.552\n",
            "   • Similitud std: 0.016\n",
            "   • Rango: [0.533, 0.594]\n",
            "   • Categorías únicas: 6/10\n",
            "   • Precisión@5 (categoría 'Electronics'): 0.00%\n",
            "   • Rating promedio: 4.05/5.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ESTADÍSTICAS FINALES"
      ],
      "metadata": {
        "id": "-NS3zl73ztGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark de velocidad\n",
        "import time\n",
        "\n",
        "# Test de velocidad: 10 búsquedas\n",
        "test_queries = [\n",
        "    \"laptop\",\n",
        "    \"headphones\",\n",
        "    \"camera\",\n",
        "    \"shoes\",\n",
        "    \"watch\"\n",
        "]\n",
        "\n",
        "print(\"\\n Benchmark de velocidad:\")\n",
        "times = []\n",
        "for query in test_queries:\n",
        "    start = time.time()\n",
        "    _ = search_by_text(query, collection, top_k=20)\n",
        "    elapsed = time.time() - start\n",
        "    times.append(elapsed)\n",
        "\n",
        "avg_time = np.mean(times)\n",
        "print(f\"   • Tiempo promedio por búsqueda: {avg_time*1000:.2f} ms\")\n",
        "print(f\"   • Búsquedas por segundo: {1/avg_time:.1f}\")\n",
        "\n",
        "# Capacidad del sistema\n",
        "print(f\"\\n Capacidad del sistema:\")\n",
        "print(f\"   • Productos indexados: {collection.count():,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvzFBvwuzsqz",
        "outputId": "50ebf39e-916b-4df9-b8ca-52143afbdaa5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Benchmark de velocidad:\n",
            "\n",
            "Búsqueda por texto: 'laptop'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.502\n",
            "   Similitud máxima: 0.559\n",
            "   Similitud mínima: 0.467\n",
            "\n",
            "Búsqueda por texto: 'headphones'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.476\n",
            "   Similitud máxima: 0.523\n",
            "   Similitud mínima: 0.447\n",
            "\n",
            "Búsqueda por texto: 'camera'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.485\n",
            "   Similitud máxima: 0.561\n",
            "   Similitud mínima: 0.462\n",
            "\n",
            "Búsqueda por texto: 'shoes'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.440\n",
            "   Similitud máxima: 0.516\n",
            "   Similitud mínima: 0.404\n",
            "\n",
            "Búsqueda por texto: 'watch'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.463\n",
            "   Similitud máxima: 0.531\n",
            "   Similitud mínima: 0.441\n",
            "   • Tiempo promedio por búsqueda: 12.12 ms\n",
            "   • Búsquedas por segundo: 82.5\n",
            "\n",
            " Capacidad del sistema:\n",
            "   • Productos indexados: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfJyWSKT2as6"
      },
      "source": [
        "## 7. Re-ranking de Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicación de un mecanismo de refinamiento mediante un modelo cross-encoder. Permite realizar la comparación cualitativa \"antes y después\" exigida, analizando críticamente cuándo el re-ranking mejora la relevancia de los productos frente a la búsqueda inicial."
      ],
      "metadata": {
        "id": "WeGws-10jWWF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "wC-6fBXf2as6"
      },
      "outputs": [],
      "source": [
        "def rerank_results(query, results, top_k=10):\n",
        "    \"\"\"\n",
        "    Re-ranking usando cross-encoder para mejorar relevancia.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    query : str\n",
        "        Consulta original del usuario\n",
        "    results : dict\n",
        "        Resultados iniciales de ChromaDB\n",
        "    top_k : int\n",
        "        Número de resultados finales después del re-ranking\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    dict\n",
        "        Resultados reordenados con scores\n",
        "    \"\"\"\n",
        "    print(f\"\\nAplicar re-ranking con cross-encoder\")\n",
        "    print(f\"   Candidatos iniciales: {len(results['documents'][0])}\")\n",
        "    print(f\"   Top-k final: {top_k}\")\n",
        "\n",
        "    documents = results['documents'][0]\n",
        "    metadatas = results['metadatas'][0]\n",
        "\n",
        "    # Preparar pares query-documento\n",
        "    pairs = [[query, doc] for doc in documents]\n",
        "\n",
        "    # Calcular scores con cross-encoder\n",
        "    print(f\"   Calcular scores de relevancia\")\n",
        "    scores = reranker.predict(pairs)\n",
        "\n",
        "    # Ordenar por score descendente\n",
        "    ranked_indices = np.argsort(scores)[::-1][:top_k]\n",
        "\n",
        "    # Reordenar resultados\n",
        "    reranked_results = {\n",
        "        'documents': [[documents[i] for i in ranked_indices]],\n",
        "        'metadatas': [[metadatas[i] for i in ranked_indices]],\n",
        "        'scores': [scores[i] for i in ranked_indices],\n",
        "        'original_indices': ranked_indices.tolist()\n",
        "    }\n",
        "\n",
        "    # Estadísticas\n",
        "    avg_score = np.mean(reranked_results['scores'])\n",
        "    max_score = np.max(reranked_results['scores'])\n",
        "\n",
        "    print(f\"    Re-ranking completado\")\n",
        "    print(f\"    Score promedio: {avg_score:.4f}\")\n",
        "    print(f\"    Score máximo: {max_score:.4f}\")\n",
        "\n",
        "    return reranked_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Comparación antes/después del re-ranking"
      ],
      "metadata": {
        "id": "fX6SZ76h2gvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"laptop for gaming high performance\"\n",
        "\n",
        "initial_results = search_by_text(query, collection, top_k=20)\n",
        "\n",
        "print(\" ANTES del Re-ranking (Top 5):\")\n",
        "for i, meta in enumerate(initial_results['metadatas'][0][:5], 1):\n",
        "    print(f\"{i}. {meta['name']}\")\n",
        "\n",
        "# Re-ranking\n",
        "reranked = rerank_results(query, initial_results, top_k=5)\n",
        "\n",
        "print(\"\\nDESPUÉS del Re-ranking (Top 5):\")\n",
        "for i, (meta, score) in enumerate(zip(reranked['metadatas'][0], reranked['scores']), 1):\n",
        "    print(f\"{i}. {meta['name']} (score: {score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZnpM1F62e0t",
        "outputId": "99153c74-efcd-42ce-8c46-0877590cd631"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Búsqueda por texto: 'laptop for gaming high performance'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.542\n",
            "   Similitud máxima: 0.610\n",
            "   Similitud mínima: 0.501\n",
            " ANTES del Re-ranking (Top 5):\n",
            "1. Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offers, Black\n",
            "2. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Blue\n",
            "3. Certified Refurbished Amazon Fire TV with Alexa Voice Remote\n",
            "4. Kindle E-reader - White, 6 Glare-Free Touchscreen Display, Wi-Fi - Includes Special Offers\n",
            "5. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Black\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 20\n",
            "   Top-k final: 5\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -9.9376\n",
            "    Score máximo: -8.6702\n",
            "\n",
            "DESPUÉS del Re-ranking (Top 5):\n",
            "1. Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offers, Black (score: -8.6702)\n",
            "2. Amazon Fire TV Gaming Edition Streaming Media Player (score: -9.5813)\n",
            "3. Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Blue Kid-Proof Case (score: -9.9898)\n",
            "4. All-New Fire 7 Tablet with Alexa, 7\" Display, 8 GB - Marine Blue (score: -10.7165)\n",
            "5. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 32 GB - Includes Special Offers, Blue (score: -10.7305)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ves6zrM2as6"
      },
      "source": [
        "## 8. Generación Aumentada por Recuperación (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai"
      ],
      "metadata": {
        "id": "yUxhKBo49nxJ"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construcción de una respuesta justificativa basada en los productos mejor posicionados. El sistema utiliza el contexto recuperado para generar una recomendación grounded (bien fundamentada)."
      ],
      "metadata": {
        "id": "G61cGT52jgim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "def generate_rag_response_gemini(query, top_products, api_key=None):\n",
        "    \"\"\"\n",
        "    Versión optimizada para modelos Gemini 3 Flash con soporte de precios.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if api_key is None:\n",
        "            api_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # 1. Normalización de datos\n",
        "        productos_lista = []\n",
        "        if isinstance(top_products, dict) and 'metadatas' in top_products:\n",
        "            productos_lista = top_products['metadatas'][0]\n",
        "        elif isinstance(top_products, list):\n",
        "            productos_lista = top_products\n",
        "\n",
        "        if not productos_lista:\n",
        "            return \"No se encontraron productos en el inventario.\"\n",
        "\n",
        "        # 2. Construcción del Contexto CON INFORMACIÓN DE PRECIO\n",
        "        contexto_text = \"\"\n",
        "        for i, p in enumerate(productos_lista[:5], 1):  # Aumentado a 5 productos\n",
        "            name = p.get('name', 'N/A')\n",
        "            price = p.get('price', 'N/A')\n",
        "            brand = p.get('brand', 'N/A')\n",
        "            category = p.get('category', 'N/A')\n",
        "            rating = p.get('avg_rating', 'N/A')\n",
        "            num_reviews = p.get('num_reviews', 0)\n",
        "            reviews = p.get('contexto_rag', 'Sin reseñas')[:200]\n",
        "\n",
        "            contexto_text += f\"\"\"PRODUCTO {i}: {name}\n",
        " PRECIO: {price}\n",
        " MARCA: {brand}\n",
        " CATEGORÍA: {category}\n",
        " RATING: {rating}/5.0 ({num_reviews} reseñas)\n",
        " OPINIONES: {reviews}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        # 3. Prompt MEJORADO con instrucciones sobre precios\n",
        "        prompt = f\"\"\"Actúa como un experto asistente de compras.\n",
        "Responde a la consulta del usuario basándote EXCLUSIVAMENTE en el contexto proporcionado.\n",
        "\n",
        "IMPORTANTE:\n",
        "- Si te preguntan por precios, SIEMPRE menciona el precio exacto en tu respuesta\n",
        "- Si preguntan \"cuál es el más barato\", compara los precios y recomienda el de menor costo\n",
        "- Si preguntan \"cuál es el más caro\", compara y recomienda el de mayor precio\n",
        "- Usa los ratings y opiniones para justificar tu recomendación\n",
        "- Si el contexto no tiene la respuesta, admítelo claramente\n",
        "\n",
        "CONTEXTO DE PRODUCTOS:\n",
        "{contexto_text}\n",
        "\n",
        "CONSULTA DEL USUARIO: \"{query}\"\n",
        "\n",
        "RESPUESTA JUSTIFICADA (menciona precios cuando sea relevante):\"\"\"\n",
        "\n",
        "        # 4. LLAMADA AL MODELO\n",
        "        model = genai.GenerativeModel('gemini-3-flash-preview')\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG - Error: {e}\")\n",
        "        # Fallback\n",
        "        return f\"Sugerencia rápida: {productos_lista[0].get('name') if productos_lista else 'No hay datos'}\""
      ],
      "metadata": {
        "id": "o106DrWE4xIO"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Ejemplo de RAG"
      ],
      "metadata": {
        "id": "DKkPPywy5hhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_rag = \"wireless bluetooth headphones with noise canceling\"\n",
        "print(f\"\\n Query: '{query_rag}'\")\n",
        "print()\n",
        "\n",
        "# Obtener productos (retrieval + re-ranking)\n",
        "initial = search_by_text(query_rag, collection, top_k=20)\n",
        "reranked = rerank_results(query_rag, initial, top_k=5)\n",
        "\n",
        "print(f\"Productos recuperados: {len(reranked['metadatas'][0])}\")\n",
        "print(f\"Top producto: {reranked['metadatas'][0][0]['name']}\\n\")\n",
        "\n",
        "try:\n",
        "    rag_response_gemini = generate_rag_response_gemini(\n",
        "        query_rag,\n",
        "        reranked\n",
        "        # api_key=GEMINI_API_KEY  # Descomentar si usas key hardcoded\n",
        "    )\n",
        "\n",
        "    print(\" Respuesta Gemini:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(rag_response_gemini)\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  No se pudo usar Gemini: {e}\")\n",
        "    print(\"   Continuando con opción 2...\")\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "jYmDVsjk888g",
        "outputId": "e4e2e7db-884d-40ae-ce38-eb13c166397a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Query: 'wireless bluetooth headphones with noise canceling'\n",
            "\n",
            "\n",
            "Búsqueda por texto: 'wireless bluetooth headphones with noise canceling'\n",
            "   Resultados encontrados: 20\n",
            "   Similitud promedio: 0.526\n",
            "   Similitud máxima: 0.577\n",
            "   Similitud mínima: 0.504\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 20\n",
            "   Top-k final: 5\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -10.5790\n",
            "    Score máximo: -8.2539\n",
            "Productos recuperados: 5\n",
            "Top producto: Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-3-flash-preview:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 31899.15ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Respuesta Gemini:\n",
            "--------------------------------------------------------------------------------\n",
            "Lo siento, pero basándome **exclusivamente** en el contexto proporcionado, no hay ningún producto que coincida con tu búsqueda de **\"wireless bluetooth headphones with noise canceling\"** (auriculares inalámbricos con cancelación de ruido).\n",
            "\n",
            "La lista de productos disponibles incluye únicamente altavoces inteligentes, tabletas y lectores de libros electrónicos:\n",
            "\n",
            "1.  **Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker**: $115 (Altavoz portátil).\n",
            "2.  **Echo Dot (Previous generation)**: $293 (Electrónica de consumo).\n",
            "3.  **All-new Echo (2nd Generation)**: $135 (Altavoz inteligente).\n",
            "4.  **All-New Fire HD 8 Tablet**: $59 (Tableta).\n",
            "5.  **All-New Kindle Oasis E-reader**: $190 (E-reader).\n",
            "\n",
            "Admito claramente que el contexto no contiene auriculares de ningún tipo.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXySXFS2as7"
      },
      "source": [
        "## 9. Búsqueda Conversacional con Contexto"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementación de la gestión de estado para conservar el \"ancla\" de la sesión (producto inicial) y las restricciones acumuladas, como colores o precios. Se permite el refinamiento iterativo (ej: \"ahora en color blanco\")."
      ],
      "metadata": {
        "id": "CbGP_huPjlSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "pvDTYlU82as7"
      },
      "outputs": [],
      "source": [
        "class ConversationalSearchSession:\n",
        "    \"\"\"\n",
        "    Maneja el contexto de búsqueda conversacional.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.anchor_query = None\n",
        "        self.constraints = {}\n",
        "        self.history = []\n",
        "        self.last_results = None\n",
        "\n",
        "    def add_turn(self, query, results):\n",
        "        \"\"\"Agregar turno a la historia.\"\"\"\n",
        "        self.history.append({'query': query, 'results': results})\n",
        "        if len(self.history) > 3:\n",
        "            self.history.pop(0)\n",
        "        self.last_results = results\n",
        "\n",
        "    def update_constraints(self, query):\n",
        "        \"\"\"Extraer restricciones del query.\"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        # Detectar colores\n",
        "        colors = ['red', 'blue', 'white', 'black', 'green', 'rojo', 'azul', 'blanco', 'negro']\n",
        "        for color in colors:\n",
        "            if color in query_lower:\n",
        "                self.constraints['color'] = color\n",
        "\n",
        "        # Detectar precio\n",
        "        if any(word in query_lower for word in ['cheap', 'barato', 'budget']):\n",
        "            self.constraints['price'] = 'low'\n",
        "        elif any(word in query_lower for word in ['expensive', 'premium', 'caro']):\n",
        "            self.constraints['price'] = 'high'\n",
        "\n",
        "    def build_contextual_query(self, current_query):\n",
        "        \"\"\"Construir query enriquecido con contexto.\"\"\"\n",
        "        self.update_constraints(current_query)\n",
        "\n",
        "        enriched = current_query\n",
        "\n",
        "        # Agregar ancla\n",
        "        if self.anchor_query and self.anchor_query.lower() not in current_query.lower():\n",
        "            enriched = f\"{self.anchor_query} {current_query}\"\n",
        "\n",
        "        # Agregar restricciones\n",
        "        for constraint, value in self.constraints.items():\n",
        "            if value not in enriched.lower():\n",
        "                enriched += f\" {value}\"\n",
        "\n",
        "        return enriched\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reiniciar sesión.\"\"\"\n",
        "        self.anchor_query = None\n",
        "        self.constraints = {}\n",
        "        self.history = []\n",
        "        self.last_results = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Ejemplo de búsqueda conversacional"
      ],
      "metadata": {
        "id": "bAAn3Dau4RoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "session = ConversationalSearchSession()\n",
        "\n",
        "# Turno 1\n",
        "query1 = \"running shoes\"\n",
        "print(f\"Usuario: {query1}\")\n",
        "results1 = search_by_text(query1, collection, top_k=10)\n",
        "reranked1 = rerank_results(query1, results1, top_k=3)\n",
        "session.anchor_query = query1\n",
        "session.add_turn(query1, reranked1)\n",
        "print(f\" Sistema: Top 1 - {reranked1['metadatas'][0][0]['name']}\\n\")\n",
        "\n",
        "# Turno 2: Refinamiento\n",
        "query2 = \"in white color\"\n",
        "print(f\" Usuario: {query2}\")\n",
        "contextual_query = session.build_contextual_query(query2)\n",
        "print(f\" Query contextual: '{contextual_query}'\")\n",
        "results2 = search_by_text(contextual_query, collection, top_k=10)\n",
        "reranked2 = rerank_results(contextual_query, results2, top_k=3)\n",
        "session.add_turn(query2, reranked2)\n",
        "print(f\" Sistema: Top 1 - {reranked2['metadatas'][0][0]['name']}\\n\")\n",
        "\n",
        "print(f\"Contexto acumulado: {session.constraints}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Ni-yV44Q1A",
        "outputId": "28276e64-e8e2-492a-c2d1-5fa7047b502f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuario: running shoes\n",
            "\n",
            "Búsqueda por texto: 'running shoes'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.467\n",
            "   Similitud máxima: 0.527\n",
            "   Similitud mínima: 0.433\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 10\n",
            "   Top-k final: 3\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -11.3032\n",
            "    Score máximo: -11.2842\n",
            " Sistema: Top 1 - All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Includes Special Offers, Blue\n",
            "\n",
            " Usuario: in white color\n",
            " Query contextual: 'running shoes in white color'\n",
            "\n",
            "Búsqueda por texto: 'running shoes in white color'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.433\n",
            "   Similitud máxima: 0.517\n",
            "   Similitud mínima: 0.399\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 10\n",
            "   Top-k final: 3\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -10.5345\n",
            "    Score máximo: -9.3831\n",
            " Sistema: Top 1 - Amazon Echo (1st Generationcertified) Color:White Free Shipping\n",
            "\n",
            "Contexto acumulado: {'color': 'white'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### GENERAR IMÁGENES DEL PRODUCTO EN DIFERENTES"
      ],
      "metadata": {
        "id": "Rix6j-fZ_Ft4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de Stable Diffusion para generación de imágenes\n",
        "!pip install -U \"diffusers<0.25.0\" transformers accelerate\n",
        "\n",
        "# Para mostrar imágenes generadas\n",
        "!pip install -q matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-4Fh8pdC_Cu5",
        "outputId": "f4279121-9055-4b8c-ab2b-71ef2cb846de"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers<0.25.0\n",
            "  Downloading diffusers-0.24.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (1.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (8.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers<0.25.0) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->diffusers<0.25.0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->diffusers<0.25.0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->diffusers<0.25.0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->diffusers<0.25.0) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->diffusers<0.25.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->diffusers<0.25.0) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers<0.25.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers<0.25.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers<0.25.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers<0.25.0) (2026.1.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.4->diffusers<0.25.0) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.19.4->diffusers<0.25.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.19.4->diffusers<0.25.0) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading diffusers-0.24.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.36.0\n",
            "    Uninstalling diffusers-0.36.0:\n",
            "      Successfully uninstalled diffusers-0.36.0\n",
            "Successfully installed diffusers-0.24.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "diffusers"
                ]
              },
              "id": "3685ac4d191c4f2695572e579c9ec967"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Variable global para el pipeline (se carga una sola vez)\n",
        "image_generation_pipeline = None\n",
        "\n",
        "def initialize_image_generator():\n",
        "    \"\"\"\n",
        "    Inicializa el generador de imágenes (solo una vez).\n",
        "    \"\"\"\n",
        "    global image_generation_pipeline\n",
        "\n",
        "    if image_generation_pipeline is None:\n",
        "        print(\" Inicializando Stable Diffusion...\")\n",
        "        print(\" Esto puede tomar 1-2 minutos la primera vez...\")\n",
        "\n",
        "        # Usar modelo más ligero para Colab\n",
        "        model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "        image_generation_pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            safety_checker=None  # Desactivar para productos\n",
        "        )\n",
        "\n",
        "        # Mover a GPU si está disponible\n",
        "        if torch.cuda.is_available():\n",
        "            image_generation_pipeline = image_generation_pipeline.to(\"cuda\")\n",
        "            print(\" Pipeline cargado en GPU\")\n",
        "        else:\n",
        "            print(\" GPU no disponible, usando CPU (será más lento)\")\n",
        "\n",
        "        print(\" Generador de imágenes listo\")\n",
        "\n",
        "    return image_generation_pipeline\n",
        "\n",
        "def generate_product_image(product_name, color, category=\"product\"):\n",
        "    \"\"\"\n",
        "    Genera una imagen del producto en el color especificado.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    product_name : str\n",
        "        Nombre del producto\n",
        "    color : str\n",
        "        Color deseado (ej: 'white', 'black', 'red')\n",
        "    category : str\n",
        "        Categoría del producto (ej: 'laptop', 'headphones')\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    PIL.Image\n",
        "        Imagen generada\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Inicializar pipeline si no existe\n",
        "        pipe = initialize_image_generator()\n",
        "\n",
        "        # Crear prompt optimizado\n",
        "        prompt = f\"professional product photography of {color} {product_name}, {category}, studio lighting, white background, high quality, detailed, 4k\"\n",
        "\n",
        "        # Prompt negativo para mejor calidad\n",
        "        negative_prompt = \"low quality, blurry, watermark, text, logo, human, person, hands\"\n",
        "\n",
        "        print(f\" Generando imagen: {color} {product_name}...\")\n",
        "\n",
        "        # Generar imagen\n",
        "        with torch.autocast(\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "            image = pipe(\n",
        "                prompt=prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                num_inference_steps=30,  # Menos pasos para más velocidad\n",
        "                guidance_scale=7.5,\n",
        "                width=512,\n",
        "                height=512\n",
        "            ).images[0]\n",
        "\n",
        "        print(\" Imagen generada exitosamente\")\n",
        "        return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error generando imagen: {e}\")\n",
        "        # Crear imagen de placeholder\n",
        "        placeholder = Image.new('RGB', (512, 512), color='lightgray')\n",
        "        return placeholder\n",
        "\n",
        "def display_generated_image(image, title=\"Producto Generado\"):\n",
        "    \"\"\"\n",
        "    Muestra la imagen generada.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UrtTDZJbEHAi"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhmQHglK2as7"
      },
      "source": [
        "## 10. Interfaz de Usuario con Gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diseño de la interfaz gráfica conversacional que integra todos los componentes del sistema. Permite al usuario subir imágenes, ingresar texto y visualizar tanto los resultados reordenados como la respuesta justificativa generada por el módulo RAG."
      ],
      "metadata": {
        "id": "UUJ_kPRijqcO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o45PRVzh2as7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f62be152-40b0-460c-9cca-18b855db3bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0ecd8fd8f17771aafb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0ecd8fd8f17771aafb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 416, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1139, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 119, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 105, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 385, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 284, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7e4eb8555d90 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Buscar top-20 productos similares\n",
            "Cargar imagen desde archivo local\n",
            " Imagen cargada exitosamente: (450, 450)\n",
            "    Resultados encontrados: 20\n",
            "    Similitud promedio: 0.675\n",
            "    Similitud máxima: 0.804\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 20\n",
            "   Top-k final: 10\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -11.3199\n",
            "    Score máximo: -10.9565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 416, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1139, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 119, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 105, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 385, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 284, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7e4eb8555d90 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Buscar top-20 productos similares\n",
            "Cargar imagen desde archivo local\n",
            " Imagen cargada exitosamente: (450, 450)\n",
            "    Resultados encontrados: 20\n",
            "    Similitud promedio: 0.675\n",
            "    Similitud máxima: 0.804\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 20\n",
            "   Top-k final: 10\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -11.3199\n",
            "    Score máximo: -10.9565\n",
            "   Buscar top-20 productos similares\n",
            "Cargar imagen desde archivo local\n",
            " Imagen cargada exitosamente: (450, 450)\n",
            "    Resultados encontrados: 20\n",
            "    Similitud promedio: 0.675\n",
            "    Similitud máxima: 0.804\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 20\n",
            "   Top-k final: 10\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -11.3199\n",
            "    Score máximo: -10.9565\n"
          ]
        }
      ],
      "source": [
        "# Sistema conversacional global\n",
        "global_session = ConversationalSearchSession()\n",
        "\n",
        "def search_interface(query_text, query_image, use_reranking, chat_history):\n",
        "    \"\"\"\n",
        "    Interfaz principal de búsqueda multimodal con:\n",
        "    - Texto / Imagen\n",
        "    - Contexto conversacional\n",
        "    - Re-ranking opcional\n",
        "    - RAG\n",
        "    - Generación de imágenes por color (cuando el usuario lo solicita)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ============================\n",
        "        # 1. DETECCIÓN DE INTENCIÓN (imagen por color)\n",
        "        generate_image = False\n",
        "        color_requested = None\n",
        "\n",
        "        query_lower = query_text.lower() if query_text else \"\"\n",
        "\n",
        "        color_keywords = {\n",
        "            'blanco': 'white', 'white': 'white',\n",
        "            'negro': 'black', 'black': 'black',\n",
        "            'rojo': 'red', 'red': 'red',\n",
        "            'azul': 'blue', 'blue': 'blue',\n",
        "            'verde': 'green', 'green': 'green',\n",
        "            'gris': 'gray', 'gray': 'gray',\n",
        "            'rosa': 'pink', 'pink': 'pink'\n",
        "        }\n",
        "\n",
        "        image_triggers = [\n",
        "            'muéstrame', 'mostrar', 'ver', 'generar',\n",
        "            'show me', 'generate', 'imagen'\n",
        "        ]\n",
        "\n",
        "        if query_text and any(t in query_lower for t in image_triggers):\n",
        "            for keyword, color in color_keywords.items():\n",
        "                if keyword in query_lower:\n",
        "                    generate_image = True\n",
        "                    color_requested = color\n",
        "                    break\n",
        "\n",
        "        # ============================\n",
        "        # 2. DETERMINAR TIPO DE BÚSQUEDA\n",
        "        # ============================\n",
        "        if query_image is not None:\n",
        "            results = search_by_image(query_image, collection, top_k=20)\n",
        "            search_type = \"imagen\"\n",
        "            query_for_rerank = \"producto similar a la imagen\"\n",
        "\n",
        "        elif query_text:\n",
        "            contextual_query = global_session.build_contextual_query(query_text)\n",
        "            results = search_by_text(contextual_query, top_k=20)\n",
        "            search_type = \"texto\"\n",
        "            query_for_rerank = contextual_query\n",
        "\n",
        "        else:\n",
        "            return \"Por favor ingresa un texto o sube una imagen.\", \"\", chat_history\n",
        "\n",
        "        # ============================\n",
        "        # 3. RE-RANKING\n",
        "        # ============================\n",
        "        if use_reranking:\n",
        "            results = rerank_results(query_for_rerank, results, top_k=10)\n",
        "            ranking_info = \" Re-ranking aplicado\"\n",
        "        else:\n",
        "            ranking_info = \" Sin re-ranking\"\n",
        "\n",
        "        # ============================\n",
        "        # 4. CONTEXTO CONVERSACIONAL\n",
        "        # ============================\n",
        "        global_session.add_turn(query_text or \"[imagen]\", results)\n",
        "\n",
        "        # ============================\n",
        "        # 5. RAG\n",
        "        # ============================\n",
        "        rag_response = generate_rag_response_gemini(\n",
        "            query_text or \"productos similares\",\n",
        "            results\n",
        "        )\n",
        "\n",
        "        # ============================\n",
        "        # 6. FORMATEO DE RESULTADOS\n",
        "        # ============================\n",
        "        output = f\"**🔍 Búsqueda por {search_type}** | {ranking_info}\\n\\n\"\n",
        "\n",
        "        # ============================\n",
        "        # 7. GENERACIÓN DE IMAGEN (SI APLICA)\n",
        "        # ============================\n",
        "        if generate_image and color_requested and results['metadatas'][0]:\n",
        "            top_product = results['metadatas'][0][0]\n",
        "\n",
        "            product_name = top_product['name']\n",
        "            category = top_product.get('category', 'product')\n",
        "\n",
        "            output += (\n",
        "                f\" **Generando imagen de '{product_name}' \"\n",
        "                f\"en color {color_requested}...**\\n\\n\"\n",
        "            )\n",
        "\n",
        "            generated_image = generate_product_image(\n",
        "                product_name,\n",
        "                color_requested,\n",
        "                category\n",
        "            )\n",
        "\n",
        "            import os\n",
        "            temp_dir = \"/tmp/generated_images\"\n",
        "            os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "            image_path = (\n",
        "                f\"{temp_dir}/{color_requested}_\"\n",
        "                f\"{product_name[:30].replace(' ', '_')}.png\"\n",
        "            )\n",
        "\n",
        "            generated_image.save(image_path)\n",
        "\n",
        "            output += f\"Imagen generada: `{image_path}`\\n\\n\"\n",
        "\n",
        "            rag_response = (\n",
        "                f\" He generado una visualización del producto \"\n",
        "                f\"**{product_name}** en color **{color_requested}**.\\n\\n\"\n",
        "                f\"{rag_response}\"\n",
        "            )\n",
        "\n",
        "        # ============================\n",
        "        # 8. TOP RESULTADOS\n",
        "        # ============================\n",
        "        output += \"**Top 5 Resultados:**\\n\\n\"\n",
        "\n",
        "        for i, meta in enumerate(results['metadatas'][0][:5], 1):\n",
        "            output += f\"**{i}. {meta['name']}**\\n\"\n",
        "            output += f\"     Categoría: {meta.get('category', 'N/A')}\\n\"\n",
        "            output += f\"     Precio: {meta.get('price', 'N/A')}\\n\"\n",
        "\n",
        "            if 'avg_rating' in meta:\n",
        "                output += (\n",
        "                    f\"     Rating: {meta['avg_rating']}/5.0 \"\n",
        "                    f\"({meta.get('num_reviews', 0)} reseñas)\\n\"\n",
        "                )\n",
        "\n",
        "            if 'scores' in results:\n",
        "                output += f\"     Score: {results['scores'][i-1]:.4f}\\n\"\n",
        "\n",
        "            output += \"\\n\"\n",
        "\n",
        "        # ============================\n",
        "        # 9. HISTORIAL\n",
        "        # ============================\n",
        "        chat_history.append(\n",
        "            (query_text or \"[Imagen subida]\", rag_response)\n",
        "        )\n",
        "\n",
        "        return output, rag_response, chat_history\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\" Error: {str(e)}\", \"\", chat_history\n",
        "def reset_session():\n",
        "    \"\"\"Reiniciar sesión conversacional.\"\"\"\n",
        "    global_session.reset()\n",
        "    return [], \"Sesión reiniciada. Contexto limpiado.\"\n",
        "\n",
        "# Crear interfaz Gradio\n",
        "with gr.Blocks(title=\"Sistema Multimodal E-Commerce\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    #  Sistema de Recuperación Multimodal para E-Commerce\n",
        "\n",
        "    **Búsqueda inteligente con contexto conversacional**\n",
        "\n",
        "    -  Búsqueda por texto\n",
        "    -  Búsqueda por imagen\n",
        "    -  Re-ranking automático\n",
        "    -  Respuestas generadas con RAG\n",
        "    -  Contexto conversacional\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            query_text = gr.Textbox(\n",
        "                label=\"Búsqueda por Texto\",\n",
        "                placeholder=\"Ej: wireless headphones bluetooth\",\n",
        "                lines=2\n",
        "            )\n",
        "            query_image = gr.Image(\n",
        "                label=\"Búsqueda por Imagen\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "            use_reranking = gr.Checkbox(\n",
        "                label=\"Aplicar Re-ranking\",\n",
        "                value=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                search_btn = gr.Button(\" Buscar\", variant=\"primary\")\n",
        "                reset_btn = gr.Button(\" Reiniciar Sesión\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            results_output = gr.Markdown(label=\"Resultados\")\n",
        "            rag_output = gr.Markdown(label=\"Recomendación AI\")\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"###  Historial Conversacional\")\n",
        "    chatbot = gr.Chatbot(label=\"Conversación\", height=300)\n",
        "\n",
        "    # Eventos\n",
        "    search_btn.click(\n",
        "        fn=search_interface,\n",
        "        inputs=[query_text, query_image, use_reranking, chatbot],\n",
        "        outputs=[results_output, rag_output, chatbot]\n",
        "    )\n",
        "\n",
        "    reset_btn.click(\n",
        "        fn=reset_session,\n",
        "        outputs=[chatbot, rag_output]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    ** Consejos de uso:**\n",
        "    - Para refinar búsquedas, usa frases como \"en color blanco\" o \"más barato\"\n",
        "    - El sistema mantiene contexto de los últimos 3 turnos\n",
        "    - Puedes combinar texto e imagen para búsquedas híbridas\n",
        "    \"\"\")\n",
        "\n",
        "# Lanzar interfaz\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "laptop for gaming high performance"
      ],
      "metadata": {
        "id": "CUayZhpIHJYT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h8wLPOE2as8"
      },
      "source": [
        "## 11. Análisis y Evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se evalúa la calidad del retrieval, se discuten limitaciones del sistema (como ruido en las imágenes o ambigüedad textual)"
      ],
      "metadata": {
        "id": "rzg5nlOejtd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "OBpJxzRV2as8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbd7f09-7aae-4299-afdf-484f3d341a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ANÁLISIS CUALITATIVO DEL SISTEMA\n",
            "\n",
            "\n",
            "Query: 'laptop for gaming'\n",
            "\n",
            "Búsqueda por texto: 'laptop for gaming'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.578\n",
            "   Similitud máxima: 0.620\n",
            "   Similitud mínima: 0.548\n",
            "\n",
            "SIN Re-ranking (Top 3):\n",
            "  1. Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offe\n",
            "  2. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Inclu\n",
            "  3. Certified Refurbished Amazon Fire TV with Alexa Voice Remote\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 10\n",
            "   Top-k final: 3\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -6.0096\n",
            "    Score máximo: -5.3446\n",
            "\n",
            "CON Re-ranking (Top 3):\n",
            "  1. Fire Tablet, 7 Display, Wi-Fi, 16 GB - Includes Special Offe... (score: -5.345)\n",
            "  2. Amazon Fire TV Gaming Edition Streaming Media Player... (score: -5.742)\n",
            "  3. Fire Kids Edition Tablet, 7 Display, Wi-Fi, 16 GB, Blue Kid-... (score: -6.943)\n",
            "\n",
            "============================================================\n",
            "\n",
            "Query: 'wireless bluetooth earbuds'\n",
            "\n",
            "Búsqueda por texto: 'wireless bluetooth earbuds'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.508\n",
            "   Similitud máxima: 0.548\n",
            "   Similitud mínima: 0.491\n",
            "\n",
            "SIN Re-ranking (Top 3):\n",
            "  1. Certified Refurbished Amazon Fire TV with Alexa Voice Remote\n",
            "  2. Oem Amazon Kindle Power Usb Adapter Wall Travel Charger Fire\n",
            "  3. Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 10\n",
            "   Top-k final: 3\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -9.2043\n",
            "    Score máximo: -5.5686\n",
            "\n",
            "CON Re-ranking (Top 3):\n",
            "  1. Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker... (score: -5.569)\n",
            "  2. Amazon Kindle Charger Power Adapter Wall Charger And Usb Cab... (score: -11.009)\n",
            "  3. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Inclu... (score: -11.036)\n",
            "\n",
            "============================================================\n",
            "\n",
            "Query: 'running shoes comfortable'\n",
            "\n",
            "Búsqueda por texto: 'running shoes comfortable'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.498\n",
            "   Similitud máxima: 0.567\n",
            "   Similitud mínima: 0.462\n",
            "\n",
            "SIN Re-ranking (Top 3):\n",
            "  1. Certified Refurbished Amazon Fire TV with Alexa Voice Remote\n",
            "  2. Kindle E-reader - White, 6 Glare-Free Touchscreen Display, W\n",
            "  3. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Inclu\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 10\n",
            "   Top-k final: 3\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -11.2936\n",
            "    Score máximo: -11.2811\n",
            "\n",
            "CON Re-ranking (Top 3):\n",
            "  1. All-New Kindle Oasis E-reader - 7 High-Resolution Display (3... (score: -11.281)\n",
            "  2. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Inclu... (score: -11.283)\n",
            "  3. All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi, 16 GB - Inclu... (score: -11.317)\n",
            "\n",
            "============================================================\n",
            "\n",
            "Query: 'kitchen blender powerful'\n",
            "\n",
            "Búsqueda por texto: 'kitchen blender powerful'\n",
            "   Resultados encontrados: 10\n",
            "   Similitud promedio: 0.500\n",
            "   Similitud máxima: 0.539\n",
            "   Similitud mínima: 0.473\n",
            "\n",
            "SIN Re-ranking (Top 3):\n",
            "  1. Certified Refurbished Amazon Fire TV with Alexa Voice Remote\n",
            "  2. Kindle E-reader - White, 6 Glare-Free Touchscreen Display, W\n",
            "  3. Amazon Echo (1st Generationcertified) Color:White Free Shipp\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 10\n",
            "   Top-k final: 3\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -10.5547\n",
            "    Score máximo: -9.8127\n",
            "\n",
            "CON Re-ranking (Top 3):\n",
            "  1. Amazon Echo ‚Äì White... (score: -9.813)\n",
            "  2. Amazon Echo (1st Generationcertified) Color:White Free Shipp... (score: -10.713)\n",
            "  3. Amazon Kindle Replacement Power Adapter (Fits Latest Generat... (score: -11.138)\n",
            "\n",
            "============================================================\n",
            "\n",
            " Análisis completado\n"
          ]
        }
      ],
      "source": [
        "# Análisis del impacto del re-ranking\n",
        "print(\"\\n ANÁLISIS CUALITATIVO DEL SISTEMA\\n\")\n",
        "\n",
        "\n",
        "# Casos de prueba\n",
        "test_queries = [\n",
        "    \"laptop for gaming\",\n",
        "    \"wireless bluetooth earbuds\",\n",
        "    \"running shoes comfortable\",\n",
        "    \"kitchen blender powerful\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "\n",
        "\n",
        "    # Sin re-ranking\n",
        "    initial = search_by_text(query,collection, top_k=10)\n",
        "    print(\"\\nSIN Re-ranking (Top 3):\")\n",
        "    for i, meta in enumerate(initial['metadatas'][0][:3], 1):\n",
        "        print(f\"  {i}. {meta['name'][:60]}\")\n",
        "\n",
        "    # Con re-ranking\n",
        "    reranked = rerank_results(query, initial, top_k=3)\n",
        "    print(\"\\nCON Re-ranking (Top 3):\")\n",
        "    for i, (meta, score) in enumerate(zip(reranked['metadatas'][0], reranked['scores']), 1):\n",
        "        print(f\"  {i}. {meta['name'][:60]}... (score: {score:.3f})\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "print(\"\\n Análisis completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thxkhGe12as8"
      },
      "source": [
        "## 12. Exportar Resultados para Informe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se exportan ejemplos de consultas, resultados y el impacto cuantitativo/cualitativo del re-ranking para sustentar la documentación final"
      ],
      "metadata": {
        "id": "I8JYIJwPj29d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "QdlazXAZ2as8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069dd44d-e5f9-44f4-fa8c-ce2587f8630a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Búsqueda por texto: 'laptop for gaming'\n",
            "   Resultados encontrados: 5\n",
            "   Similitud promedio: 0.597\n",
            "   Similitud máxima: 0.620\n",
            "   Similitud mínima: 0.576\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 5\n",
            "   Top-k final: 5\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -9.8875\n",
            "    Score máximo: -5.3446\n",
            "\n",
            "Búsqueda por texto: 'wireless bluetooth earbuds'\n",
            "   Resultados encontrados: 5\n",
            "   Similitud promedio: 0.520\n",
            "   Similitud máxima: 0.548\n",
            "   Similitud mínima: 0.506\n",
            "\n",
            "Aplicar re-ranking con cross-encoder\n",
            "   Candidatos iniciales: 5\n",
            "   Top-k final: 5\n",
            "   Calcular scores de relevancia\n",
            "    Re-ranking completado\n",
            "    Score promedio: -10.0431\n",
            "    Score máximo: -5.5686\n",
            " Datos para informe exportados a 'report_data.json'\n",
            "\n",
            "Resumen del corpus:\n",
            "  - Total productos: 69\n",
            "  - Dimensión embeddings: 512\n"
          ]
        }
      ],
      "source": [
        "# Guardar ejemplos de resultados para el informe\n",
        "import json\n",
        "\n",
        "report_data = {\n",
        "    'corpus_info': {\n",
        "        'total_products': len(products_df),\n",
        "        'embedding_dimension': combined_embeddings.shape[1],\n",
        "        'categories': products_df['main_category'].value_counts().head(10).to_dict() if 'main_category' in products_df else {}\n",
        "    },\n",
        "    'example_searches': [],\n",
        "    'reranking_impact': []\n",
        "}\n",
        "\n",
        "# Ejemplos de búsquedas\n",
        "for query in test_queries[:2]:\n",
        "    initial = search_by_text(query, collection, top_k=5)\n",
        "    reranked = rerank_results(query, initial, top_k=5)\n",
        "\n",
        "    report_data['example_searches'].append({\n",
        "        'query': query,\n",
        "        'top_3_products': [\n",
        "            meta['name'] for meta in reranked['metadatas'][0][:3]\n",
        "        ]\n",
        "    })\n",
        "\n",
        "# Guardar datos\n",
        "with open('report_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(report_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\" Datos para informe exportados a 'report_data.json'\")\n",
        "print(\"\\nResumen del corpus:\")\n",
        "print(f\"  - Total productos: {report_data['corpus_info']['total_products']}\")\n",
        "print(f\"  - Dimensión embeddings: {report_data['corpus_info']['embedding_dimension']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaeUF9oX2as8"
      },
      "source": [
        "## 13. Conclusiones\n",
        "\n",
        "Este notebook implementa un sistema completo de recuperación multimodal que cumple con todos los requisitos:\n",
        "\n",
        " **Indexación multimodal**: CLIP para embeddings de texto e imagen\n",
        "\n",
        " **Búsqueda multimodal**: Texto → productos e Imagen → productos\n",
        "\n",
        " **Re-ranking**: Cross-encoder para mejorar relevancia\n",
        "\n",
        " **RAG**: Generación basada en contexto recuperado\n",
        "\n",
        " **Búsqueda conversacional**: Mantenimiento de contexto entre turnos\n",
        "\n",
        " **Interfaz de usuario**: Gradio con todas las funcionalidades\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
