{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f8b5c16e7eb563",
   "metadata": {},
   "source": [
    "# Ejercicio 6: Dense Retrieval e Introducción a FAISS\n",
    "\n",
    "## Objetivo de la práctica\n",
    "\n",
    "Generar embeddings con sentence-transformers (SBERT, E5), e indexar documentos con FAISS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd69ed7fcbeef9d",
   "metadata": {},
   "source": [
    "## Parte 0: Carga del Corpus\n",
    "### Actividad\n",
    "\n",
    "1. Carga el corpus 20 Newsgroups desde sklearn.datasets.fetch_20newsgroups.\n",
    "2. Limita el corpus a los primeros 2000 documentos para facilitar el procesamiento."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 2,
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   "id": "b00fbde6cfc88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando corpus 20 Newsgroups...\n",
      "Total de documentos cargados: 2000\n",
      "Ejemplo de documento:\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However,...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar el corpus 20 Newsgroups\n",
    "print(\"Cargando corpus 20 Newsgroups...\")\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Limitar a los primeros 2000 documentos\n",
    "documents = newsgroups.data[:2000]\n",
    "print(f\"Total de documentos cargados: {len(documents)}\")\n",
    "print(f\"Ejemplo de documento:\\n{documents[0][:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9184f4b3e66e20a",
   "metadata": {},
   "source": [
    "## Parte 2: Generación de Embeddings\n",
    "### Actividad\n",
    "\n",
    "1. Usa dos modelos de sentence-transformers. Puedes usar: `'all-MiniLM-L6-v2'` (SBERT), o `'intfloat/e5-base'` (E5). Cuando uses E5, antepon `\"passage: \"` a cada documento antes de codificar.\n",
    "2. Genera los vectores de embeddings para todos los documentos usando el modelo seleccionado.\n",
    "3. Guarda los embeddings en un array de NumPy para su posterior indexación."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "ae4a00fa-4aa3-4eb4-9b78-ca41797b1802",
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 6,
   "id": "ae4a00fa-4aa3-4eb4-9b78-ca41797b1802",
   "metadata": {},
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from sentence-transformers) (1.15.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.27.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Collecting shellingham (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jinja2 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.12.14)\n",
      "Requirement already satisfied: anyio in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.14.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/iccd332-josune/miniforge3/envs/iccd332/lib/python3.11/site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.0)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m521.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:11\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, hf-xet, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 mpmath-1.3.0 networkx-3.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 safetensors-0.7.0 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.3 triton-3.5.1\n"
=======
      "Requirement already satisfied: sentence-transformers in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\labp4e010\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "525ae7515c6169d9",
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 8,
   "id": "525ae7515c6169d9",
   "metadata": {},
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Cargando modelo SBERT: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c842f5e791514f21bd63db7fd5553fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67ffea516444bf08ec4d5d854611314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5080dc744c2241d0b7cf420a9ba310b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517176151a464f6ebdd2d6ffbb8b9e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634682c25265482a87ffe61f8201a5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074c7361003b46c58d99dd7bbe322009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0633cbec3bee43e08d282ad3502d3b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6c759d29354b138591c622fced2809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f97e350b954ff58091e7584e433c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77502da529a945029418ab959fb8c984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb1e615e5514f3ba24e612537933c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
=======
      "Cargando modelo SBERT: all-MiniLM-L6-v2...\n",
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
      "Generando embeddings con SBERT...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "4fd97ae707e846cf9354f7956465cf84",
=======
       "model_id": "0f246e912dad41a19f1bfa16338633c0",
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de embeddings SBERT: (2000, 384)\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: Usando SBERT (all-MiniLM-L6-v2)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "print(\"Cargando modelo SBERT: all-MiniLM-L6-v2...\")\n",
    "model_sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Generando embeddings con SBERT...\")\n",
    "doc_embeddings_sbert = model_sbert.encode(documents, show_progress_bar=True)\n",
    "print(f\"Dimensión de embeddings SBERT: {doc_embeddings_sbert.shape}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "0636b273-0616-4ff3-887c-fd1c9706a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar embeddings en arrays de NumPy\n",
    "np.save('embeddings_sbert.npy', doc_embeddings_sbert)\n",
    "print(\"\\nEmbeddings guardados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8810c674-0faa-4141-814c-3e23aef61359",
   "metadata": {},
=======
   "execution_count": 9,
   "id": "0636b273-0616-4ff3-887c-fd1c9706a89b",
   "metadata": {},
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
<<<<<<< HEAD
      "Cargando modelo E5: intfloat/e5-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568043f01c4746da8ea4a5da32cce6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9080f732304cacba85373ea6c7dc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bd8b7fc5414390b31341fdb97ed3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca51c3832694bbda390d7df1663b7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64c112d556a4673ae73e988406a3677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f5dab2fd954d99a47c14d07c109f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8ef261dcd04dd6b655f17be23599d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edd071b77d5451381b22a5f91225832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef30bb5db6d043e9a1286b9d4a72f3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998378a3379445b0abced7382ed85a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings con E5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c63c51e40d4d46b9eee6c4803326c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión de embeddings E5: (2000, 768)\n",
      "\n",
=======
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
      "Embeddings guardados exitosamente\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "# Guardar embeddings en arrays de NumPy\n",
    "np.save('embeddings_sbert.npy', doc_embeddings_sbert)\n",
    "print(\"\\nEmbeddings guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810c674-0faa-4141-814c-3e23aef61359",
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
    "# Opción 2: Usando E5 (intfloat/e5-base)\n",
    "print(\"\\nCargando modelo E5: intfloat/e5-base...\")\n",
    "model_e5 = SentenceTransformer('intfloat/e5-base')\n",
    " \n",
    "# Preprocesar documentos con prefijo \"passage: \" para E5\n",
    "documents_e5 = [\"passage: \" + doc for doc in documents]\n",
    "\n",
    "print(\"Generando embeddings con E5...\")\n",
    "doc_embeddings_e5 = model_e5.encode(documents_e5, show_progress_bar=True)\n",
    "print(f\"Dimensión de embeddings E5: {doc_embeddings_e5.shape}\")\n",
    "\n",
    "# Guardar embeddings en arrays de NumPy\n",
    "np.save('embeddings_e5.npy', doc_embeddings_e5)\n",
    "print(\"\\nEmbeddings guardados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b50365064d2b1",
   "metadata": {},
   "source": [
    "## Parte 3: Indexación con FAISS\n",
    "### Actividad\n",
    "\n",
    "1. Crea un índice plano con faiss.IndexFlatL2 para búsquedas por distancia euclidiana.\n",
    "2. Asegúrate de usar la dimensión correcta `(embedding_dim = doc_embeddings.shape[1])`.\n",
    "3. Agrega los vectores de documentos al índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c723e6189ab1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40462a067ca2d379",
   "metadata": {},
   "source": [
    "## Parte 4: Consulta Semántica\n",
    "### Actividad\n",
    "\n",
    "1. Escribe una consulta en lenguaje natural. Ejemplos:\n",
    "\n",
    "    * \"God, religion, and spirituality\"\n",
    "    * \"space exploration\"\n",
    "    * \"car maintenance\"\n",
    "\n",
    "2. Codifica la consulta utilizando el mismo modelo de embeddings. Cuando uses E5, antepon `\"query: \"` a la consulta.\n",
    "3. Recupera los 5 documentos más relevantes con `index.search(...)`.\n",
    "4. Muestra los textos de los documentos recuperados (puedes mostrar solo los primeros 500 caracteres de cada uno)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 10,
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   "id": "aad085806124c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, model, doc_embeddings, documents, top_k=5, use_e5=False):\n",
    "    # Codificar la consulta\n",
    "    if use_e5:\n",
    "        query_text = \"query: \" + query\n",
    "    else:\n",
    "        query_text = query\n",
    "    \n",
    "    query_embedding = model.encode([query_text])\n",
    "    \n",
    "    # Calcular similitud coseno\n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "    \n",
    "    # Obtener los índices de los top_k documentos más similares\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    return top_indices, similarities[top_indices]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 12,
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   "id": "be897fb2-b841-40c2-ad79-ad19c2351f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "BÚSQUEDAS CON SBERT (all-MiniLM-L6-v2)\n",
=======
      "\n",
      "======================================================================\n",
      "BÚSQUEDAS CON SBERT (all-MiniLM-L6-v2)\n",
      "======================================================================\n",
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
      "CONSULTA: 'God, religion, and spirituality'\n",
      "Resultado #1 (Similitud: 0.4150)\n",
      "Documento #996\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Humanist, or sub-humanist? :-)...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #2 (Similitud: 0.3307)\n",
      "Documento #282\n",
      "\n",
      "I didn't know God was a secular humanist...\n",
      "\n",
      "Kent...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #3 (Similitud: 0.3013)\n",
      "Documento #677\n",
      " \n",
      "(Deletion)\n",
      " \n",
      "For me, it is a \"I believe no gods exist\" and a \"I don't believe gods exist\".\n",
      " \n",
      "In other words, I think that statements like gods are or somehow interfere\n",
      "with this world are false or meaningless. In Ontology, one can fairly\n",
      "conclude that when \"A exist\" is meaningless A does not exist. Under the\n",
      "Pragmatic definition of truth, \"A exists\" is meaningless makes A exist\n",
      "even logically false.\n",
      " \n",
      "A problem with such statements is that one can't disprove a subjective god\n",
      "by definition, and...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #4 (Similitud: 0.2878)\n",
      "Documento #943\n",
      "\n",
      "\n",
      "Atoms are not objective.  They aren't even real.  What scientists call\n",
      "an atom is nothing more than a mathematical model that describes \n",
      "certain physical, observable properties of our surroundings.  All\n",
      "of which is subjective.  \n",
      "\n",
      "What is objective, though, is the approach a scientist \n",
      "takes in discussing his model and his observations.  There\n",
      "is no objective science.  But there is an objective approach\n",
      "which is subjectively selected by the scientist.  Objective\n",
      "in this case means a specified, ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #5 (Similitud: 0.2856)\n",
      "Documento #791\n",
      "Above all, love each other deeply, because love covers over a multitude of\n",
      "sins. ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "CONSULTA: 'space exploration'\n",
      "Resultado #1 (Similitud: 0.4991)\n",
      "Documento #495\n",
      "I am posting this for a friend without internet access. Please inquire\n",
      "to the phone number and address listed.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\"Space: Teaching's Newest Frontier\"\n",
      "Sponsored by the Planetary Studies Foundation\n",
      "\n",
      "The Planetary Studies Foundation is sponsoring a one week class for\n",
      "teachers called \"Space: Teaching's Newest Frontier.\" The class will be\n",
      "held at the Sheraton Suites in Elk Grove, Illinois from June 14 through\n",
      "June 18. Participants wh...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #2 (Similitud: 0.4398)\n",
      "Documento #1643\n",
      "\n",
      "Well, here goes.\n",
      "\n",
      "The first item of business is to establish the importance space life\n",
      "sciences in the whole of scheme of humankind.  I mean compared\n",
      "to football and baseball, the average joe schmoe doesn't seem interested\n",
      "or even curious about spaceflight.  I think that this forum can\n",
      "make a major change in that lack of insight and education.\n",
      "\n",
      "All of us, in our own way, can contribute to a comprehensive document\n",
      "which can be released to the general public around the world.  The\n",
      "document would ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #3 (Similitud: 0.4321)\n",
      "Documento #786\n",
      "Ron Miller is a space artist with a long and distinguished career.  \n",
      "I've admired both his paintings (remember the USPS Solar System\n",
      "Exploration Stamps last year?) and his writings on the history of\n",
      "spaceflight.  For several years he's been working on a *big* project\n",
      "which is almost ready to hit the streets.  A brochure from his\n",
      "publisher has landed in my mailbox, and I thought it was cool enough\n",
      "to type in part of it (it's rather long).  Especially given the Net's\n",
      "strong interest in vaporware s...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #4 (Similitud: 0.3995)\n",
      "Documento #1199\n",
      "Any comments on the absorbtion of the Office of Exploration into the\n",
      "Office of Space Sciences and the reassignment of Griffin to the \"Chief\n",
      "Engineer\" position?  Is this just a meaningless administrative\n",
      "shuffle, or does this bode ill for SEI?\n",
      "\n",
      "In my opinion, this seems like a Bad Thing, at least on the surface.\n",
      "Griffin seemed to be someone who was actually interested in getting\n",
      "things done, and who was willing to look an innovative approaches to\n",
      "getting things done faster, better, and cheaper.  ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #5 (Similitud: 0.3746)\n",
      "Documento #25\n",
      "AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\n",
      "May 7th  at Crystal City Virginia, under the auspices of AIAA.\n",
      "\n",
      "Does anyone know more about this?  How much, to attend????\n",
      "\n",
      "Anyone want to go?...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "CONSULTA: 'car maintenance'\n",
      "Resultado #1 (Similitud: 0.4879)\n",
      "Documento #1822\n",
      "As you can see, I have two 1987 cars, both worth about $3000 each.\n",
      "The problem is that maintenance costs on these two cars is\n",
      "running about $4000 per year and insurance $3000 per year.\n",
      "\n",
      "What am I doing wrong?\n",
      "\n",
      "Within the last two months, the follows costs have occured:\n",
      "\n",
      "Dodge 600 SE (Dodge's attempt at the American German car!)\n",
      "\n",
      "$1,000 - replace head gasket\n",
      "$300   - new radiator\n",
      "\n",
      "Chevy Nova CL (Chevy's attempt at a Japan import!)\n",
      "\n",
      "$500 - tune-up,oil change,valve gasket,middle exhaust pipe, misc....\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #2 (Similitud: 0.4467)\n",
      "Documento #1470\n",
      "Archive-name: rec-autos/part1\n",
      "\n",
      "[most recent changes, 15 March 1993: addition of alt.autos.karting -- rpw]\n",
      "\n",
      "               === Welcome to Rec.Autos.* ===\n",
      "\n",
      "This article is sent out automatically each month, and contains a general\n",
      "description of the purpose of each of the automotive newsgroups, and\n",
      "some suggested guidelines for discussions.  The keywords `Monthly Posting'\n",
      "will always appear to make killing this article easy for users of\n",
      "newsreaders with kill facilities.  This article is posted to a...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #3 (Similitud: 0.4061)\n",
      "Documento #43\n",
      "Archive-name: rec-autos/part3\n",
      "\n",
      "The Automotive Articles Archive Server:\n",
      "\n",
      "the automotive archive server is in the process of being rehosted,\n",
      "and is presently not available....\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #4 (Similitud: 0.3863)\n",
      "Documento #1368\n",
      "} maintenance) and probably didn't know the answer at the start of the thread.\n",
      "\n",
      "\tUh, Doug, I don't know what school of thought your from, but chain \n",
      "drive are MUCH more efficient than shafties.  End of story.  Period.\n",
      "\tBut I will give you that shafties are much less maintenance intensive...\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tEthan...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #5 (Similitud: 0.3806)\n",
      "Documento #1296\n",
      "\n",
      "There was a Volvo owner that had $3000 dollars worth of improvements to the \n",
      "looks of the car by hail :).\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"God, religion, and spirituality\",\n",
    "    \"space exploration\",\n",
    "    \"car maintenance\"\n",
    "]\n",
    "\n",
<<<<<<< HEAD
    "print(\"BÚSQUEDAS CON SBERT (all-MiniLM-L6-v2)\")\n",
=======
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BÚSQUEDAS CON SBERT (all-MiniLM-L6-v2)\")\n",
    "print(\"=\"*70)\n",
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
    "\n",
    "for query in queries:\n",
    "    print(f\"CONSULTA: '{query}'\")\n",
    "    \n",
    "    indices, scores = search_documents(\n",
    "        query, \n",
    "        model_sbert, \n",
    "        doc_embeddings_sbert, \n",
    "        documents, \n",
    "        top_k=5\n",
    "    )\n",
    "    \n",
    "    for rank, (idx, score) in enumerate(zip(indices, scores), 1):\n",
    "        print(f\"Resultado #{rank} (Similitud: {score:.4f})\")\n",
    "        print(f\"Documento #{idx}\")\n",
    "        print(f\"{documents[idx][:500]}...\")\n",
<<<<<<< HEAD
    "        print(f\"{'-'*70}\\n\")\n"
=======
    "        print(f\"{'-'*70}\\n\")\n",
    "\n",
    "\n",
    "\n"
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "id": "ef3c6d47-7f4e-47cb-b1a6-f1c6d0a658c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BÚSQUEDAS CON E5 (intfloat/e5-base)\n",
      "\n",
      "======================================================================\n",
      "CONSULTA: 'God, religion, and spirituality'\n",
      "======================================================================\n",
      "\n",
      "Resultado #1 (Similitud: 0.8287)\n",
      "Documento #171\n",
      "\n",
      "    But no one (or at least, not many people) are trying to pass off God\n",
      "as a scientific fact.  Not so with Kirlian photography.  I'll admit that\n",
      "it is possible that some superior intelligence exists elsewhere, and if\n",
      "people want to label that intelligence \"God\", I'm not going to stop\n",
      "them.  Anyway, let's _not_ turn this into a theological debate.  ;-)\n",
      "\n",
      "\n",
      "    Read alt.fan.robert.mcelwaine sometime.  I've never been so\n",
      "closed-minded before subscribing to that group.  :)\n",
      "...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #2 (Similitud: 0.8223)\n",
      "Documento #1883\n",
      "...\n",
      "\n",
      "\n",
      "Seems to me if you learned to differentiate between illusion and\n",
      "reality on your own you wouldn't need to rely on doctrines that\n",
      "need to be updated.  My experience of Christianity (25+ years) is\n",
      "that most Christians seek answers from clergymen who have little\n",
      "or no direct experience of spiritual matters, and that most of\n",
      "these questions can be answered by simple introspection.  Most\n",
      "people suspect that they cannot trust their senses, but few take\n",
      "the next step to figure out that they can t...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #3 (Similitud: 0.8212)\n",
      "Documento #1961\n",
      "I am writing a paper on religion and how it reflects \n",
      "and or affects modern music.  This brief questionaire is summary of\n",
      "the questions I would like answered.  A response is requested and \n",
      "can be mailed to me directly at: \n",
      "                   \n",
      "                    gtd259a@prism.gatech.edu \n",
      "          \n",
      "                   *PLEASE MAIL - DO NOT POST*\n",
      "\n",
      "Thanks in advance,\n",
      "Matt Kressel\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1.) How do you feel about groups like Diecide,...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #4 (Similitud: 0.8184)\n",
      "Documento #419\n",
      "\n",
      "\tOne of the things I find intersting about pagan beliefs is\n",
      "their belief in a feminine deity as well as a masculine deity. Being\n",
      "brought up in a Christian household, I often wondered if there was God\n",
      "the Father, where was the mother? Everyone I know who has a father\n",
      "usually as a mother. It just seemed rather unbalanced to me. \n",
      "\tFortunately, my own personal theology, which will probably not\n",
      "fall into line with a lot others, recognized God as a being both\n",
      "without gender and posessing qualities of...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #5 (Similitud: 0.8178)\n",
      "Documento #1971\n",
      "Hi!\n",
      "\n",
      "\tAnyone know anything about the Interdisciplinary Bible Research\n",
      "Institute, operating out of Hatfield, Pa?\n",
      "\n",
      "\tI'm really interested in their theories on old-earth\n",
      "(as opposed to young earth) and what they believe about evolution.\n",
      "\n",
      "\tThanks,\n",
      "\t\tIn the Master,\n",
      "\n",
      "\t\tCharley.\n",
      "\n",
      "\n",
      "--\n",
      "       Seek God and you will find, among other things,\n",
      "                          piercing pleasure.\n",
      "       \n",
      "       Seek pleasure and you will find boredom, disillusionment        \n",
      "                      and enslavement.\n",
      "   ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CONSULTA: 'space exploration'\n",
      "======================================================================\n",
      "\n",
      "Resultado #1 (Similitud: 0.8190)\n",
      "Documento #25\n",
      "AW&ST  had a brief blurb on a Manned Lunar Exploration confernce\n",
      "May 7th  at Crystal City Virginia, under the auspices of AIAA.\n",
      "\n",
      "Does anyone know more about this?  How much, to attend????\n",
      "\n",
      "Anyone want to go?...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #2 (Similitud: 0.8179)\n",
      "Documento #1643\n",
      "\n",
      "Well, here goes.\n",
      "\n",
      "The first item of business is to establish the importance space life\n",
      "sciences in the whole of scheme of humankind.  I mean compared\n",
      "to football and baseball, the average joe schmoe doesn't seem interested\n",
      "or even curious about spaceflight.  I think that this forum can\n",
      "make a major change in that lack of insight and education.\n",
      "\n",
      "All of us, in our own way, can contribute to a comprehensive document\n",
      "which can be released to the general public around the world.  The\n",
      "document would ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #3 (Similitud: 0.8150)\n",
      "Documento #495\n",
      "I am posting this for a friend without internet access. Please inquire\n",
      "to the phone number and address listed.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\"Space: Teaching's Newest Frontier\"\n",
      "Sponsored by the Planetary Studies Foundation\n",
      "\n",
      "The Planetary Studies Foundation is sponsoring a one week class for\n",
      "teachers called \"Space: Teaching's Newest Frontier.\" The class will be\n",
      "held at the Sheraton Suites in Elk Grove, Illinois from June 14 through\n",
      "June 18. Participants wh...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #4 (Similitud: 0.8094)\n",
      "Documento #390\n",
      "As for SF and advertising in space. There is a romantic episode\n",
      "in Mead's \"The Big Ball of Wax\" where the lovers are watching \n",
      "the constellation Pepsi Cola rising over the horizon and noting\n",
      "the some 'stars' had slipped cause the Teamsters were on strike.\n",
      "\n",
      "This was the inspiration for my article on orbiting a formation\n",
      "of space mirrors published in Spaceflight in 1986. As the reviews\n",
      "but is it aesthetically desirable?  These days the only aesthetics\n",
      "that count are the ones you can count!...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #5 (Similitud: 0.8084)\n",
      "Documento #784\n",
      "\n",
      "Whatabout, Schools, Universities, Rich Individuals (around 250 people \n",
      "in the UK have more than 10 million dollars each). I reecieved mail\n",
      "from people who claimed they might get a person into space for $500\n",
      "per pound. Send a skinny person into space and split the rest of the money\n",
      "among the ground crew!\n",
      "Agreed. I volunteer for any UK attempts. But one clause: No launch methods\n",
      "which are clearly dangerous to the environment (ours or someone else's). No\n",
      "usage of materials from areas of planetary ...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CONSULTA: 'car maintenance'\n",
      "======================================================================\n",
      "\n",
      "Resultado #1 (Similitud: 0.8285)\n",
      "Documento #1822\n",
      "As you can see, I have two 1987 cars, both worth about $3000 each.\n",
      "The problem is that maintenance costs on these two cars is\n",
      "running about $4000 per year and insurance $3000 per year.\n",
      "\n",
      "What am I doing wrong?\n",
      "\n",
      "Within the last two months, the follows costs have occured:\n",
      "\n",
      "Dodge 600 SE (Dodge's attempt at the American German car!)\n",
      "\n",
      "$1,000 - replace head gasket\n",
      "$300   - new radiator\n",
      "\n",
      "Chevy Nova CL (Chevy's attempt at a Japan import!)\n",
      "\n",
      "$500 - tune-up,oil change,valve gasket,middle exhaust pipe, misc....\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #2 (Similitud: 0.8113)\n",
      "Documento #1029\n",
      "\n",
      "You can avoid these problems entirely by installing an oil drain valve in\n",
      "place of the bolt.  I have one on both of my cars.  There have been no\n",
      "leaks in 210,000 miles (combined miles on both cars)....\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #3 (Similitud: 0.8053)\n",
      "Documento #1368\n",
      "} maintenance) and probably didn't know the answer at the start of the thread.\n",
      "\n",
      "\tUh, Doug, I don't know what school of thought your from, but chain \n",
      "drive are MUCH more efficient than shafties.  End of story.  Period.\n",
      "\tBut I will give you that shafties are much less maintenance intensive...\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tEthan...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #4 (Similitud: 0.8011)\n",
      "Documento #43\n",
      "Archive-name: rec-autos/part3\n",
      "\n",
      "The Automotive Articles Archive Server:\n",
      "\n",
      "the automotive archive server is in the process of being rehosted,\n",
      "and is presently not available....\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultado #5 (Similitud: 0.7998)\n",
      "Documento #520\n",
      "\n",
      "When will people learn!\n",
      "\n",
      "The trouble is the ballast in the concrete and as every fool knows Ballast \n",
      "resistors are used to discharge batteries. Furthermore it is very silly to \n",
      "store the battery with the terminals downwards as you must have done to \n",
      "contact the ballast. \n",
      "\n",
      "Seriously: self discharge (the actual problem, as stated by others) does vary \n",
      "greatly with certain types and freaks show low self discharge. I have in \n",
      "fact seen ordinary automotive batteries which have effectively held full ...\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"BÚSQUEDAS CON E5 (intfloat/e5-base)\")\n",
=======
   "execution_count": null,
   "id": "ef3c6d47-7f4e-47cb-b1a6-f1c6d0a658c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BÚSQUEDAS CON E5 (intfloat/e5-base)\")\n",
    "print(\"=\"*70)\n",
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CONSULTA: '{query}'\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    indices, scores = search_documents(\n",
    "        query, \n",
    "        model_e5, \n",
    "        doc_embeddings_e5, \n",
    "        documents, \n",
    "        top_k=5,\n",
    "        use_e5=True\n",
    "    )\n",
    "    \n",
    "    for rank, (idx, score) in enumerate(zip(indices, scores), 1):\n",
    "        print(f\"Resultado #{rank} (Similitud: {score:.4f})\")\n",
    "        print(f\"Documento #{idx}\")\n",
    "        print(f\"{documents[idx][:500]}...\")\n",
    "        print(f\"{'-'*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "id": "2e2d1879-3f25-47b4-a7d9-375ab9d45ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS COMPARATIVO\n",
      "\n",
      "Comparando resultados para: 'space exploration'\n",
      "\n",
      "Top 5 con SBERT:\n",
      "  1. Doc #495 - Similitud: 0.4991\n",
      "  2. Doc #1643 - Similitud: 0.4398\n",
      "  3. Doc #786 - Similitud: 0.4321\n",
      "  4. Doc #1199 - Similitud: 0.3995\n",
      "  5. Doc #25 - Similitud: 0.3746\n",
      "\n",
      "Top 5 con E5:\n",
      "  1. Doc #25 - Similitud: 0.8190\n",
      "  2. Doc #1643 - Similitud: 0.8179\n",
      "  3. Doc #495 - Similitud: 0.8150\n",
      "  4. Doc #390 - Similitud: 0.8094\n",
      "  5. Doc #784 - Similitud: 0.8084\n",
      "\n",
      "Documentos en común: 3/5\n"
     ]
    }
   ],
   "source": [
    "print(\"ANÁLISIS COMPARATIVO\")\n",
=======
   "execution_count": null,
   "id": "2e2d1879-3f25-47b4-a7d9-375ab9d45ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Comparación de resultados\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANÁLISIS COMPARATIVO\")\n",
    "print(\"=\"*70)\n",
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
    "\n",
    "test_query = \"space exploration\"\n",
    "print(f\"\\nComparando resultados para: '{test_query}'\\n\")\n",
    "\n",
    "# SBERT\n",
    "indices_sbert, scores_sbert = search_documents(\n",
    "    test_query, model_sbert, doc_embeddings_sbert, documents, top_k=5\n",
    ")\n",
    "\n",
    "# E5\n",
    "indices_e5, scores_e5 = search_documents(\n",
    "    test_query, model_e5, doc_embeddings_e5, documents, top_k=5, use_e5=True\n",
    ")\n",
    "\n",
    "print(\"Top 5 con SBERT:\")\n",
    "for rank, (idx, score) in enumerate(zip(indices_sbert, scores_sbert), 1):\n",
    "    print(f\"  {rank}. Doc #{idx} - Similitud: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 con E5:\")\n",
    "for rank, (idx, score) in enumerate(zip(indices_e5, scores_e5), 1):\n",
    "    print(f\"  {rank}. Doc #{idx} - Similitud: {score:.4f}\")\n",
    "\n",
    "# Calcular overlap\n",
    "overlap = len(set(indices_sbert) & set(indices_e5))\n",
    "print(f\"\\nDocumentos en común: {overlap}/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9e5e7815c7508",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
<<<<<<< HEAD
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
=======
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.10"
=======
   "version": "3.13.5"
>>>>>>> 8a5ea6ca3446b31d15f355da166f45a936fceee7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
