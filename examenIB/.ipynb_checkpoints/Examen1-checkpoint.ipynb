{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf1b3753200bfaf",
   "metadata": {},
   "source": [
    "# ICCD753 Recuperación de Información 2025-B\n",
    "# Examen Bimestral - Sistema Básico de Recuperación de Información\n",
    "### Base de datos: Rotten Tomatoes movies and critic reviews\n",
    "## Josune Singaña"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b12582fd51a10",
   "metadata": {},
   "source": [
    "## PARTE 1: IMPORTACIÓN DE LIBRERÍAS Y CONFIGURACIÓN INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6868cb6a-244c-4d7d-99e2-080b016fe4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# --- CONFIGURACIÓN INICIAL ---\n",
    "def inicializar_recursos():\n",
    "    try:\n",
    "        nltk.data.find('corpora/stopwords')\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "    \n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Inicializamos al importar la librería\n",
    "inicializar_recursos()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be7dae-566a-44ee-9f4a-3f2f7b12588b",
   "metadata": {},
   "source": [
    "## PARTE 2: CARGA Y PREPROCESAMIENTO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43bd8365-6b02-4e77-aa56-6634ec5cc83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Películas cargadas: 17712 registros\n",
      " Reviews cargadas: 1130017 registros\n",
      "\n",
      "--- Columnas de Movies ---\n",
      "['rotten_tomatoes_link', 'movie_title', 'movie_info', 'critics_consensus', 'content_rating', 'genres', 'directors', 'authors', 'actors', 'original_release_date', 'streaming_release_date', 'runtime', 'production_company', 'tomatometer_status', 'tomatometer_rating', 'tomatometer_count', 'audience_status', 'audience_rating', 'audience_count', 'tomatometer_top_critics_count', 'tomatometer_fresh_critics_count', 'tomatometer_rotten_critics_count']\n",
      "\n",
      "--- Columnas de Reviews ---\n",
      "['rotten_tomatoes_link', 'critic_name', 'top_critic', 'publisher_name', 'review_type', 'review_score', 'review_date', 'review_content']\n",
      "\n",
      "--- Muestra de Películas ---\n",
      "  rotten_tomatoes_link                                        movie_title  \\\n",
      "0            m/0814255  Percy Jackson & the Olympians: The Lightning T...   \n",
      "1            m/0878835                                        Please Give   \n",
      "2                 m/10                                                 10   \n",
      "\n",
      "                                          movie_info  \\\n",
      "0  Always trouble-prone, the life of teenager Per...   \n",
      "1  Kate (Catherine Keener) and her husband Alex (...   \n",
      "2  A successful, middle-aged Hollywood songwriter...   \n",
      "\n",
      "                                   critics_consensus content_rating  \\\n",
      "0  Though it may seem like just another Harry Pot...             PG   \n",
      "1  Nicole Holofcener's newest might seem slight i...              R   \n",
      "2  Blake Edwards' bawdy comedy may not score a pe...              R   \n",
      "\n",
      "                                              genres          directors  \\\n",
      "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
      "1                                             Comedy  Nicole Holofcener   \n",
      "2                                    Comedy, Romance      Blake Edwards   \n",
      "\n",
      "                                      authors  \\\n",
      "0  Craig Titley, Chris Columbus, Rick Riordan   \n",
      "1                           Nicole Holofcener   \n",
      "2                               Blake Edwards   \n",
      "\n",
      "                                              actors original_release_date  \\\n",
      "0  Logan Lerman, Brandon T. Jackson, Alexandra Da...            2010-02-12   \n",
      "1  Catherine Keener, Amanda Peet, Oliver Platt, R...            2010-04-30   \n",
      "2  Dudley Moore, Bo Derek, Julie Andrews, Robert ...            1979-10-05   \n",
      "\n",
      "   ...      production_company  tomatometer_status tomatometer_rating  \\\n",
      "0  ...        20th Century Fox              Rotten               49.0   \n",
      "1  ...  Sony Pictures Classics     Certified-Fresh               87.0   \n",
      "2  ...             Waner Bros.               Fresh               67.0   \n",
      "\n",
      "  tomatometer_count  audience_status  audience_rating audience_count  \\\n",
      "0             149.0          Spilled             53.0       254421.0   \n",
      "1             142.0          Upright             64.0        11574.0   \n",
      "2              24.0          Spilled             53.0        14684.0   \n",
      "\n",
      "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
      "0                             43                               73   \n",
      "1                             44                              123   \n",
      "2                              2                               16   \n",
      "\n",
      "   tomatometer_rotten_critics_count  \n",
      "0                                76  \n",
      "1                                19  \n",
      "2                                 8  \n",
      "\n",
      "[3 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datasets\n",
    "df_movies = pd.read_csv('rotten_tomatoes_movies.csv')\n",
    "df_reviews = pd.read_csv('rotten_tomatoes_critic_reviews.csv')\n",
    "\n",
    "print(f\"\\n Películas cargadas: {len(df_movies)} registros\")\n",
    "print(f\" Reviews cargadas: {len(df_reviews)} registros\")\n",
    "\n",
    "# Explorar estructura de datos\n",
    "print(\"\\n--- Columnas de Movies ---\")\n",
    "print(df_movies.columns.tolist())\n",
    "print(\"\\n--- Columnas de Reviews ---\")\n",
    "print(df_reviews.columns.tolist())\n",
    "\n",
    "# Vista previa\n",
    "print(\"\\n--- Muestra de Películas ---\")\n",
    "print(df_movies.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f508c3-74f6-43bc-8d27-27ae79cfa6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.1 Limpia datos de películas\n",
      "Columnas identificadas para procesamiento: ['movie_title', 'genres']\n",
      "\n",
      "2.2 Agrega reviews de críticos...\n",
      "ID Movies: rotten_tomatoes_link, ID Reviews: rotten_tomatoes_link\n",
      "\n",
      "✓ Texto combinado creado para 17712 películas\n",
      "\n",
      "2.3 Tokenizando corpus...\n",
      "\n",
      "--- ESTADÍSTICAS DE PREPROCESAMIENTO ---\n",
      "Documentos procesados: 17712\n",
      "Tokens totales: 1,228,506\n",
      "Vocabulario único: 12,919\n",
      "Promedio tokens/doc: 69.4\n"
     ]
    }
   ],
   "source": [
    "stop_words = set([\n",
    "    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',\n",
    "    'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "    'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "    'should', 'may', 'might', 'can', 'this', 'that', 'these', 'those', 'i',\n",
    "    'you', 'he', 'she', 'it', 'we', 'they', 'what', 'which', 'who', 'when',\n",
    "    'where', 'why', 'how', 'all', 'each', 'every', 'both', 'few', 'more',\n",
    "    'most', 'other', 'some', 'such', 'than', 'too', 'very', 'just', 'its'\n",
    "])\n",
    "\n",
    "# --- FUNCIONES DE PREPROCESAMIENTO ---\n",
    "def procesar_texto_seguro(texto):\n",
    "    # Limpieza robusta: Minúsculas -> Sin HTML -> Sin signos -> Tokenización -> Stopwords\"\"\"\n",
    "    if not isinstance(texto, str): \n",
    "        return []\n",
    "    \n",
    "    text = texto.lower()\n",
    "    text = re.sub(pattern=r\"<.*?>\", repl='', string=text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    tokens = text.split()\n",
    "    tokens_filtrados = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "    \n",
    "    return tokens_filtrados\n",
    "\n",
    "# 2.1 Limpiar datos de películas\n",
    "print(\"\\n2.1 Limpia datos de películas\")\n",
    "\n",
    "# Identificar columnas relevantes (ajustar según tu dataset)\n",
    "columnas_texto = []\n",
    "for col in df_movies.columns:\n",
    "    if any(keyword in col.lower() for keyword in ['title', 'genre', 'synopsis', 'description', 'movie_title']):\n",
    "        columnas_texto.append(col)\n",
    "\n",
    "print(f\"Columnas identificadas para procesamiento: {columnas_texto}\")\n",
    "\n",
    "# Crear columna combinada de texto\n",
    "df_movies['texto_combinado'] = ''\n",
    "for col in columnas_texto:\n",
    "    if col in df_movies.columns:\n",
    "        df_movies['texto_combinado'] += ' ' + df_movies[col].fillna('').astype(str)\n",
    "\n",
    "# 2.2 Agregar reviews de críticos\n",
    "print(\"\\n2.2 Agrega reviews de críticos...\")\n",
    "\n",
    "# Identificar columna de ID común\n",
    "id_col_movies = None\n",
    "id_col_reviews = None\n",
    "\n",
    "for col in df_movies.columns:\n",
    "    if 'id' in col.lower() or 'rotten_tomatoes' in col.lower():\n",
    "        id_col_movies = col\n",
    "        break\n",
    "\n",
    "for col in df_reviews.columns:\n",
    "    if 'id' in col.lower() or 'rotten_tomatoes' in col.lower():\n",
    "        id_col_reviews = col\n",
    "        break\n",
    "\n",
    "print(f\"ID Movies: {id_col_movies}, ID Reviews: {id_col_reviews}\")\n",
    "\n",
    "# Agrupar reviews por película\n",
    "if id_col_reviews:\n",
    "    review_text_col = [col for col in df_reviews.columns if 'review' in col.lower() or 'content' in col.lower()][0]\n",
    "    reviews_agrupadas = df_reviews.groupby(id_col_reviews)[review_text_col].apply(\n",
    "        lambda x: ' '.join(x.fillna('').astype(str))\n",
    "    ).reset_index()\n",
    "    reviews_agrupadas.columns = [id_col_movies, 'reviews_texto']\n",
    "    \n",
    "    # Merge con películas\n",
    "    df_movies = df_movies.merge(reviews_agrupadas, on=id_col_movies, how='left')\n",
    "    df_movies['texto_combinado'] += ' ' + df_movies['reviews_texto'].fillna('')\n",
    "\n",
    "print(f\"\\n✓ Texto combinado creado para {len(df_movies)} películas\")\n",
    "\n",
    "# 2.3 Tokenización del corpus\n",
    "print(\"\\n2.3 Tokenizando corpus...\")\n",
    "corpus_tokens = df_movies['texto_combinado'].apply(procesar_texto_seguro).tolist()\n",
    "\n",
    "# Estadísticas de preprocesamiento\n",
    "tokens_totales = sum(len(doc) for doc in corpus_tokens)\n",
    "tokens_unicos = len(set(token for doc in corpus_tokens for token in doc))\n",
    "\n",
    "print(f\"\\n--- ESTADÍSTICAS DE PREPROCESAMIENTO ---\")\n",
    "print(f\"Documentos procesados: {len(corpus_tokens)}\")\n",
    "print(f\"Tokens totales: {tokens_totales:,}\")\n",
    "print(f\"Vocabulario único: {tokens_unicos:,}\")\n",
    "print(f\"Promedio tokens/doc: {tokens_totales/len(corpus_tokens):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b31da-1b4f-4687-9852-a138ddf4e5ed",
   "metadata": {},
   "source": [
    "##  SECCIÓN 3: CONSTRUCCIÓN DEL SISTEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840ccc4-f7e6-47cc-ac99-81186dcb1ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3.1 Generando vocabulario...\n",
      "✓ Vocabulario: 12919 términos\n",
      "\n",
      "3.2 Calculando IDF...\n",
      "✓ IDF calculado para 12919 términos\n",
      "\n",
      "3.3 Generando matriz TF-IDF...\n"
     ]
    }
   ],
   "source": [
    "def obtener_vocabulario(corpus_tokens):\n",
    "   # Genera vocabulario único ordenado.\n",
    "    vocabulario = set()\n",
    "    for doc in corpus_tokens:\n",
    "        vocabulario.update(doc)\n",
    "    return sorted(list(vocabulario))\n",
    "\n",
    "def calcular_idf(corpus, vocabulario):\n",
    "    \"\"\"Calcula IDF para cada término del vocabulario.\"\"\"\n",
    "    N = len(corpus)\n",
    "    idf_dict = {}\n",
    "    \n",
    "    df_dict = dict.fromkeys(vocabulario, 0)\n",
    "    for doc in corpus:\n",
    "        for palabra in set(doc):\n",
    "            if palabra in df_dict:\n",
    "                df_dict[palabra] += 1\n",
    "                \n",
    "    for palabra, df in df_dict.items():\n",
    "        idf_dict[palabra] = math.log10(N / (df + 1))\n",
    "        \n",
    "    return idf_dict\n",
    "\n",
    "def calcular_tf(documento):\n",
    "    \"\"\"Calcula TF para un documento.\"\"\"\n",
    "    tf_dict = {}\n",
    "    largo_doc = len(documento)\n",
    "    conteo = Counter(documento)\n",
    "    \n",
    "    for palabra, count in conteo.items():\n",
    "        if largo_doc > 0:\n",
    "            tf_dict[palabra] = count / largo_doc\n",
    "        else:\n",
    "            tf_dict[palabra] = 0\n",
    "    return tf_dict\n",
    "\n",
    "def generar_matriz_tfidf(corpus):\n",
    "    \"\"\"Genera matriz TF-IDF completa.\"\"\"\n",
    "    vocab = obtener_vocabulario(corpus)\n",
    "    idf_dict = calcular_idf(corpus, vocab)\n",
    "    matriz_datos = []\n",
    "    \n",
    "    for doc in corpus:\n",
    "        tf_dict = calcular_tf(doc)\n",
    "        fila_vector = []\n",
    "        for palabra in vocab:\n",
    "            valor_tf = tf_dict.get(palabra, 0)\n",
    "            valor_idf = idf_dict[palabra]\n",
    "            fila_vector.append(valor_tf * valor_idf)\n",
    "        matriz_datos.append(fila_vector)\n",
    "        \n",
    "    return pd.DataFrame(matriz_datos, columns=vocab)\n",
    "\n",
    "# Construir sistema\n",
    "print(\"\\n3.1 Generando vocabulario...\")\n",
    "vocabulario = obtener_vocabulario(corpus_tokens)\n",
    "print(f\"✓ Vocabulario: {len(vocabulario)} términos\")\n",
    "\n",
    "print(\"\\n3.2 Calculando IDF...\")\n",
    "idf_dict = calcular_idf(corpus_tokens, vocabulario)\n",
    "print(f\"✓ IDF calculado para {len(idf_dict)} términos\")\n",
    "\n",
    "print(\"\\n3.3 Generando matriz TF-IDF...\")\n",
    "df_tfidf = generar_matriz_tfidf(corpus_tokens)\n",
    "print(f\"✓ Matriz TF-IDF: {df_tfidf.shape[0]} docs x {df_tfidf.shape[1]} términos\")\n",
    "\n",
    "# Análisis de términos más importantes\n",
    "print(\"\\n--- TÉRMINOS CON MAYOR IDF (más discriminativos) ---\")\n",
    "top_idf = sorted(idf_dict.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "for term, idf_val in top_idf:\n",
    "    print(f\"{term:20s}: {idf_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b9b18-943a-4039-8bea-1393e679e288",
   "metadata": {},
   "source": [
    "## 4: FUNCIONES DE BÚSQUEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77085270-f56a-4709-a4ca-45ee5771e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizar_consulta(consulta, vocabulario, idf_dict):\n",
    "    \"\"\"Vectoriza consulta usando TF-IDF.\"\"\"\n",
    "    tokens = procesar_texto_seguro(consulta)\n",
    "    \n",
    "    tf_val = 1 / len(tokens) if len(tokens) > 0 else 0\n",
    "    tf_query = {token: tf_val for token in tokens}\n",
    "    \n",
    "    vector_consulta = []\n",
    "    for palabra in vocabulario:\n",
    "        tf = tf_query.get(palabra, 0)\n",
    "        idf = idf_dict.get(palabra, 0)\n",
    "        vector_consulta.append(tf * idf)\n",
    "        \n",
    "    return np.array(vector_consulta)\n",
    "\n",
    "def calcular_similitud_coseno(vector_query, matriz_tfidf):\n",
    "    \"\"\"Calcula similitud coseno entre consulta y documentos.\"\"\"\n",
    "    ranking = []\n",
    "    norma_q = norm(vector_query)\n",
    "    \n",
    "    if norma_q == 0: \n",
    "        return []\n",
    "        \n",
    "    for doc_idx, row in matriz_tfidf.iterrows():\n",
    "        vector_doc = np.array(row)\n",
    "        dot_product = np.dot(vector_query, vector_doc)\n",
    "        norma_d = norm(vector_doc)\n",
    "        \n",
    "        if norma_d > 0:\n",
    "            similitud = dot_product / (norma_q * norma_d)\n",
    "        else:\n",
    "            similitud = 0\n",
    "        ranking.append((doc_idx, similitud))\n",
    "        \n",
    "    return ranking\n",
    "\n",
    "def buscar_documentos(consulta, df_tfidf, vocabulario, idf_dict, top_n=5):\n",
    "    \"\"\"Busca documentos relevantes para una consulta.\"\"\"\n",
    "    print(f\"\\nBuscando: '{consulta}'\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    vec_q = vectorizar_consulta(consulta, vocabulario, idf_dict)\n",
    "    scores = calcular_similitud_coseno(vec_q, df_tfidf)\n",
    "    ranking_ordenado = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    resultados_finales = []\n",
    "    for doc_id, score in ranking_ordenado[:top_n]:\n",
    "        if score > 0:\n",
    "            resultados_finales.append({\n",
    "                'Documento_ID': doc_id,\n",
    "                'Relevancia': round(score, 4)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(resultados_finales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e985a7-7cb7-43ff-a0a2-87855bc6ac9d",
   "metadata": {},
   "source": [
    "## 5: SIMULACIONES DE CONSULTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c08be-657d-4c6f-8a39-ddd54d998421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener columna de título\n",
    "titulo_col = [col for col in df_movies.columns if 'title' in col.lower()][0]\n",
    "\n",
    "# Consultas del examen\n",
    "consultas = [\n",
    "    \"Películas sobre viajes espaciales\",\n",
    "    \"Películas para ver en familia\",\n",
    "    \"Películas de acción y aventura\",\n",
    "    \"Comedias románticas\",\n",
    "    \"Películas de terror y suspenso\"\n",
    "]\n",
    "\n",
    "resultados_todas_consultas = {}\n",
    "\n",
    "for consulta in consultas:\n",
    "    # Buscar\n",
    "    df_resultados = buscar_documentos(consulta, df_tfidf, vocabulario, idf_dict, top_n=10)\n",
    "    \n",
    "    if len(df_resultados) > 0:\n",
    "        # Agregar información de películas\n",
    "        df_resultados['Título'] = df_resultados['Documento_ID'].apply(\n",
    "            lambda x: df_movies.iloc[x][titulo_col]\n",
    "        )\n",
    "        \n",
    "        # Reordenar columnas\n",
    "        df_resultados = df_resultados[['Documento_ID', 'Título', 'Relevancia']]\n",
    "        \n",
    "        print(f\"\\n{df_resultados.to_string(index=False)}\")\n",
    "        resultados_todas_consultas[consulta] = df_resultados\n",
    "    else:\n",
    "        print(\"No se encontraron resultados relevantes.\")\n",
    "        resultados_todas_consultas[consulta] = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea82e6c-cd17-4d51-8bdb-2e40e3129e5a",
   "metadata": {},
   "source": [
    "## 6: ANÁLISIS DE RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee126457-e6de-440d-8652-bdc36e9af86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n ANÁLISIS CUANTITATIVO:\")\n",
    "\n",
    "\n",
    "for consulta, df_res in resultados_todas_consultas.items():\n",
    "    if len(df_res) > 0:\n",
    "        avg_score = df_res['Relevancia'].mean()\n",
    "        max_score = df_res['Relevancia'].max()\n",
    "        min_score = df_res['Relevancia'].min()\n",
    "        \n",
    "        print(f\"\\nConsulta: {consulta}\")\n",
    "        print(f\"  • Resultados encontrados: {len(df_res)}\")\n",
    "        print(f\"  • Relevancia promedio: {avg_score:.4f}\")\n",
    "        print(f\"  • Relevancia máxima: {max_score:.4f}\")\n",
    "        print(f\"  • Relevancia mínima: {min_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1e057-78f6-49fc-a5cb-03b909bcc856",
   "metadata": {},
   "source": [
    "LIMITACIONES IDENTIFICADAS:\n",
    "   - El sistema es puramente léxico (no considera sinónimos)\n",
    "   -  No captura relaciones semánticas entre palabras\n",
    "- Sensible a la calidad de la metadata disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327de34a-8fa4-4f35-aaed-351e5d300610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 955509,
     "sourceId": 1617920,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
